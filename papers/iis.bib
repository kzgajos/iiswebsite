
@article{eklund2023real,
  abstract = {{Novel disease modifying therapies are being evaluated in spinocerebellar ataxias and multiple system atrophy. Clinician-performed disease rating scales are relatively insensitive for measuring disease change over time, resulting in large and long clinical trials. We tested the hypothesis that sensors worn continuously at home during natural behavior and a web-based computer mouse task performed at home could produce interpretable, meaningful, and reliable motor measures for potential use in clinical trials.Thirty-four individuals with degenerative ataxias (spinocerebellar ataxia types 1, 2, 3, and 6 and multiple system atrophy of the cerebellar type) and eight age-matched controls completed the cross-sectional study. Participants wore an ankle and wrist sensor continuously at-home for one week and completed the Hevelius computer mouse task eight times over four weeks. We examined properties of motor primitives called ``submovements'' derived from the continuous wearable sensors and properties of computer mouse clicks and trajectories in relationship to patient-reported measures of function (PROM-Ataxia) and ataxia rating scales (Scale for the Assessment and Rating of Ataxia and the Brief Ataxia Rating Scale). The test-retest reliability of digital measures and differences between ataxia and control participants were evaluated.Individuals with ataxia had smaller, slower, and less powerful ankle submovements during natural behavior at home. A composite measure based on ankle submovements strongly correlated with ataxia rating scale scores (Pearson's r = 0.82-0.88), strongly correlated with self-reported function (r = 0.81), had high test-retest reliability (intraclass correlation coefficient = 0.95), and distinguished ataxia and control participants, including preataxic individuals (N=4) from controls. A composite measure based on computer mouse movements and clicks strongly correlated with ataxia rating scale total (r = 0.86-0.88) and arm scores (r = 0.65-0.75), correlated well with self-reported function (r = 0.72-0.73), and had high test-retest reliability (intraclass correlation coefficient = 0.99).These data indicate that interpretable, meaningful, and highly reliable motor measures can be obtained from continuous measurement of natural movement, particularly at the ankle location, and from computer mouse movements during a simple point-and-click task performed at home. This study supports the use of these two inexpensive and easy-to-use technologies in longitudinal natural history studies in spinocerebellar ataxias and multiple system atrophy of the cerebellar type and shows promise as potential motor outcome measures in interventional trials.}},
  author = {Eklund, Nicole M and Ouillon, Jessey and Pandey, Vineet and Stephen, Christopher D and Schmahmann, Jeremy D and Edgerton, Jeremy and Gajos, Krzysztof Z and Gupta, Anoopum S},
  doi = {10.1093/braincomms/fcad064},
  eprint = {https://academic.oup.com/braincomms/advance-article-pdf/doi/10.1093/braincomms/fcad064/49514822/fcad064.pdf},
  issn = {2632-1297},
  journal = {Brain Communications},
    volume = {5},
    number = {2},
    year = {2023},
    month = {03},
  title = {{Real-life ankle submovements and computer mouse use reflect patient-reported function in adult ataxias}},
  url = {https://doi.org/10.1093/braincomms/fcad064},

pubtype = "journal",
publisherversion = {https://doi.org/10.1093/braincomms/fcad064},
  }

@article{pandey2023accuracy,
title = {Accuracy and Reliability of At-home Quantification of Motor Impairments Using a Computer-based Pointing Task with Children with Ataxia-Telangiectasia},
author = {Vineet Pandey and Nergis C. Khan and Anoopum S. Gupta and Krzysztof Z. Gajos},
journal = {ACM Transactions on Accessible Computing},
month = {mar}, 
articleno = {10}, 
numpages = {25},
year = {2023},
issue_date = {March 2023}, 
publisher = {Association for Computing Machinery}, 
address = {New York, NY, USA}, 
volume = {16}, 
number = {1}, 
issn = {1936-7228}, 
url = {https://doi.org/10.1145/3581790}, 
doi = {10.1145/3581790},
abstract = {Methods for obtaining accurate quantitative assessments of motor impairments are essential in accessibility research, design of adaptive ability-based assistive technologies, as well as in clinical care and medical research. Currently, such assessments are typically performed in controlled laboratory or clinical settings under professional supervision. Emerging approaches for collecting data in unsupervised settings have been shown to produce valid data when aggregated over large populations, but it is not yet established if in unsupervised settings measures of research or clinical significance can be collected accurately and reliably for individuals.
We conducted a study with 13 children with ataxia-telangiectasia and 9 healthy children to analyze the validity, test-retest reliability, and acceptability of at-home use of a recent active digital phenotyping system, called Hevelius. Hevelius produces 32 measures derived from the movement trajectories of the mouse cursor, and it produces a quantitative estimate of motor impairment in the dominant arm using the dominant arm component of the Brief Ataxia Rating Scale (BARS). 
The severity score estimates generated by Hevelius from single at-home sessions deviated from clinician-assigned BARS scores more than the severity score estimates generated from single sessions conducted under researcher supervision. However, taking a median of as few as 2 consecutive sessions produced severity score estimates that were as accurate or better than the estimates produced from single supervised sessions. Further, aggregating as few as 2 consecutive sessions resulted in good test-retest reliability (ICC = 0.81 for A-T participants).
This work demonstrated the feasibility of performing accurate and reliable quantitative assessments of individual motor impairments in the dominant arm through tasks performed at home without supervision by the researchers. Further work is needed, however, to assess how broadly these results generalize.},

pubtype = "journal",
pdf = "pandey2023accuracy.pdf",
image={http://www.eecs.harvard.edu/~kgajos/papers/images/hevelius.png},
publisherversion = {https://doi.org/10.1145/3581790},
}


@article{greenberg2023sex,
author = {David M. Greenberg  and Varun Warrier  and Ahmad Abu-Akel  and Carrie Allison  and Krzysztof Z. Gajos  and Katharina Reinecke  and P. Jason Rentfrow  and Marcin A. Radecki  and Simon Baron-Cohen },
title = {Sex and age differences in “theory of mind” across 57 countries using the English version of the “Reading the Mind in the Eyes” Test},
journal = {Proceedings of the National Academy of Sciences},
volume = {120},
number = {1},
pages = {e2022385119},
year = {2023},
doi = {10.1073/pnas.2022385119},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.2022385119},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.2022385119},
abstract = {The “Reading the Mind in the Eyes” Test (Eyes Test) is a widely used assessment of “theory of mind.” The NIMH Research Domain Criteria recommends it as one of two tests for “understanding mental states.” Previous studies have demonstrated an on-average female advantage on the Eyes Test. However, it is unknown whether this female advantage exists across the lifespan and across a large number of countries. Thus, we tested sex and age differences using the English version of the Eyes Test in adolescents and adults across 57 countries. We also tested for associations with sociodemographic and cognitive/personality factors. We leveraged one discovery dataset (N = 305,726) and three validation datasets (Ns = 642; 5,284; and 1,087). The results show that: i) there is a replicable on-average female advantage in performance on the Eyes Test; ii) performance increases through adolescence and shallowly declines across adulthood; iii) the on-average female advantage is evident across the lifespan; iv) there is a significant on-average female advantage in 36 out of 57 countries; v) there is a\&nbsp;significant on-average female advantage on translated (non-English) versions of the Eyes Test in 12 out of 16 countries, as confirmed by a systematic review; vi) D-scores, or empathizing-systemizing, predict Eyes Test performance above and beyond sex differences; and vii) the female advantage is negatively linked to “prosperity” and “autonomy,” and positively linked to “collectivism,”\&nbsp;as confirmed by exploratory country-level analyses. We conclude that the on-average female advantage on the Eyes Test is observed across ages and most countries.},

pubtype = "journal",
publisherversion = "https://www.pnas.org/doi/abs/10.1073/pnas.2022385119",
}


@Article{lin2022barriers,
author="Lin, Jody L
and Huber, Bernd
and Amir, Ofra
and Gehrmann, Sebastian
and Ramirez, Kimberly S
and Ochoa, Kimberly M
and Asch, Steven M
and Gajos, Krzysztof Z
and Grosz, Barbara J
and Sanders, Lee M",
title="Barriers and Facilitators to the Implementation of Family-Centered Technology in Complex Care: Feasibility Study",
journal="J Med Internet Res",
year="2022",
month="Aug",
day="23",
volume="24",
number="8",
pages="e30902",
keywords="care coordination; implementation science; chronic illness; pediatric; family medicine; barrier; complex care; children; families; parents; care providers; chronic disease; coordination; implementation; improvement; technology; feasibility; acceptability; monitoring",
abstract="Background: Care coordination is challenging but crucial for children with medical complexity (CMC). Technology-based solutions are increasingly prevalent but little is known about how to successfully deploy them in the care of CMC. Objective: The aim of this study was to assess the feasibility and acceptability of GoalKeeper (GK), an internet-based system for eliciting and monitoring family-centered goals for CMC, and to identify barriers and facilitators to implementation. Methods: We used the Consolidated Framework for Implementation Research (CFIR) to explore the barriers and facilitators to the implementation of GK as part of a clinical trial of GK in ambulatory clinics at a children's hospital (NCT03620071). The study was conducted in 3 phases: preimplementation, implementation (trial), and postimplementation. For the trial, we recruited providers at participating clinics and English-speaking parents of CMC<12 years of age with home internet access. All participants used GK during an initial clinic visit and for 3 months after. We conducted preimplementation focus groups and postimplementation semistructured exit interviews using the CFIR interview guide. Participant exit surveys assessed GK feasibility and acceptability on a 5-point Likert scale. For each interview, 3 independent coders used content analysis and serial coding reviews based on the CFIR qualitative analytic plan and assigned quantitative ratings to each CFIR construct (--2 strong barrier to +2 strong facilitator). Results: Preimplementation focus groups included 2 parents (1 male participant and 1 female participant) and 3 providers (1 in complex care, 1 in clinical informatics, and 1 in neurology). From focus groups, we developed 3 implementation strategies: education (parents: 5-minute demo; providers: 30-minute tutorial and 5-minute video on use in a clinic visit; both: instructional manual), tech support (in-person, virtual), and automated email reminders for parents. For implementation (April 1, 2019, to December 21, 2020), we enrolled 11 providers (7 female participants, 5 in complex care) and 35 parents (mean age 38.3, SD 7.8 years; n=28, 80{\%} female; n=17, 49{\%} Caucasian; n=16, 46{\%} Hispanic; and n=30, 86{\%} at least some college). One parent-provider pair did not use GK in the clinic visit, and few used GK after the visit. In 18 parent and 9 provider exit interviews, the key facilitators were shared goal setting, GK's internet accessibility and email reminders (parents), and GK's ability to set long-term goals and use at the end of visits (providers). A key barrier was GK's lack of integration into the electronic health record or patient portal. Most parents (13/19) and providers (6/9) would recommend GK to their peers. Conclusions: Family-centered technologies like GK are feasible and acceptable for the care of CMC, but sustained use depends on integration into electronic health records. Trial Registration: ClinicalTrials.gov NCT03620071; https://clinicaltrials.gov/ct2/show/NCT03620071 ",
issn="1438-8871",
doi="10.2196/30902",
url="https://doi.org/10.2196/30902",

pubtype = "journal",
publisherversion="https://doi.org/10.2196/30902",
}


@inproceedings{ma2022preference,
author = {Ma, Zilin and Gajos, Krzysztof Z.}, 
title = {Not Just a Preference: Reducing Biased Decision-Making on Dating Websites}, 
year = {2022}, 
isbn = {9781450391573}, 
publisher = {Association for Computing Machinery}, 
address = {New York, NY, USA}, 
url = {https://doi.org/10.1145/3491102.3517587}, 
doi = {10.1145/3491102.3517587}, 
abstract = { As dating websites are becoming an essential part of how people meet intimate and romantic partners, it is vital to design these systems to be resistant to, or at least do not amplify, bias and discrimination. Instead, the results of our online experiment with a simulated dating website, demonstrate that popular dating website design choices, such as the user of the swipe interface (swiping in one direction to indicate a like and in the other direction to express a dislike) and match scores, resulted in people racially biases choices even when they explicitly claimed not to have considered race in their decision-making. This bias was significantly reduced when the order of information presentation was reversed such that people first saw substantive profile information related to their explicitly-stated preferences before seeing the profile name and photo. These results indicate that currently-popular design choices amplify people’s implicit biases in their choices of potential romantic partners, but the effects of the implicit biases can be reduced by carefully redesigning the dating website interfaces.}, 
booktitle = {CHI Conference on Human Factors in Computing Systems}, 
articleno = {203}, 
numpages = {14}, 
keywords = {implicit bias, dating websites}, 
location = {New Orleans, LA, USA}, 
series = {CHI '22},

pubtype = {conference},
pdf = {ma2022preference.pdf},
publisherversion = {https://doi.org/10.1145/3491102.3517587}, 
image = {http://www.eecs.harvard.edu/~kgajos/papers/images/ma2022preference-thumb.png},
}

@inproceedings{gajos2022people,
author = {Gajos, Krzysztof Z. and Mamykina, Lena}, 
title = {Do People Engage Cognitively with AI? Impact of AI Assistance on Incidental Learning}, 
year = {2022}, 
isbn = {9781450391443}, 
publisher = {Association for Computing Machinery}, 
address = {New York, NY, USA}, 
url = {https://doi.org/10.1145/3490099.3511138}, 
doi = {10.1145/3490099.3511138},
pages = {794–806}, 
numpages = {13}, 
keywords = {explainable AI, cognitive engagement, incidental learning, decision support systems, human-centered AI}, 
location = {Helsinki, Finland}, 
series = {IUI '22},
abstract = {When people receive advice while making difficult decisions, they often make better decisions in the moment and also increase their knowledge in the process. However, such incidental learning can only occur when people cognitively engage with the information they receive and process this information thoughtfully. How do people process the information and advice they receive from AI, and do they engage with it deeply enough to enable learning? To answer these questions, we conducted three experiments in which individuals were asked to make nutritional decisions and received simulated AI recommendations and explanations. In the first experiment, we found that when people were presented with both a recommendation and an explanation before making their choice, they made better decisions than they did when they received no such help, but they did not learn. In the second experiment, participants first made their own choice, and only then saw a recommendation and an explanation from AI; this condition also resulted in improved decisions, but no learning. However, in our third experiment, participants were presented with just an AI explanation but no recommendation and had to arrive at their own decision. This condition led to both more accurate decisions and learning gains. We hypothesize that learning gains in this condition were due to deeper engagement with explanations needed to arrive at the decisions. This work provides some of the most direct evidence to date that it may not be sufficient to provide people with AI-generated recommendations and explanations to ensure that people engage carefully with the AI-provided information. This work also presents one technique that enables incidental learning and, by implication, can help people process AI recommendations and explanations more carefully.},

pubtype = {conference},
pdf = {gajos2022people.pdf},
publisherversion = {https://doi.org/10.1145/3490099.3511138},
image = {http://www.eecs.harvard.edu/~kgajos/papers/images/gajos2022people.png},
video-embedded={<iframe width="560" height="315" src="https://www.youtube.com/embed/H-OWOUK1VOM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>},
}


@article{ruotsalo2022active,
  abstract = {We introduce active tag recommendation for interactive entity search, an approach that actively learns to suggest tags from preceding user interactions with the recommended tags. The approach utilizes an online reinforcement learning model and observes user interactions on the recommended tags to reward or penalize the model. Active tag recommendation is implemented as part of a realistic search engine indexing a large collection of movie data. The approach is evaluated in task-based user experiments comparing a complete search system enhanced with active tag recommendation to a control system in which active tag recommendation is not available. In the experiment, participants (N = 45) performed search tasks on the movie domain and the corresponding search interactions, information selections, and entity rankings were logged and analyzed. The results show that active tag recommendation (1) improves the ranking of entities compared to written-query interaction, (2) increases the amount of interaction and effectiveness of interactions to rank entities that end up being selected in a task, and (3) reduces, but does not substitute, the need for written-query interaction (4) without compromising task execution time. The results imply that active learning for search support can help users to interact with entity search systems by reducing the need for writing queries and improve search outcomes without compromising the time used for searching.},
  author = {Tuukka Ruotsalo and Sean Weber and Krzysztof Z. Gajos},
  date-modified = {2022-02-10 06:54:55 -0500},
  doi = {https://doi.org/10.1016/j.ipm.2021.102856},
  issn = {0306-4573},
  journal = {Information Processing & Management},
  keywords = {Tag recommendation, Active learning, Information retrieval, Search user interfaces, User study},
  number = {2},
  pages = {102856},
  title = {Active tag recommendation for interactive entity search: Interaction effectiveness and retrieval performance},
  url = {https://www.sciencedirect.com/science/article/pii/S0306457321003277},
  volume = {59},
  year = {2022},
  
  pubtype = {journal},
  publisherversion = {https://doi.org/10.1016/j.ipm.2021.102856},
  }


@article{khan2022free,
  title={Free-Living Motor Activity Monitoring in Ataxia-Telangiectasia},
  author={Khan, Nergis C and Pandey, Vineet and Gajos, Krzysztof Z and Gupta, Anoopum S},
  journal={The Cerebellum},
  pages={368--379},
  volume={21},
  issue={3},
  year={2022},
  publisher={Springer},
  url = {https://doi.org/10.1007/s12311-021-01306-y},
  abstract = {With disease-modifying approaches under evaluation in ataxia-telangiectasia and other ataxias, there is a need for objective and reliable biomarkers of free-living motor function. In this study, we test the hypothesis that metrics derived from a single wrist sensor worn at home provide accurate, reliable, and interpretable information about neurological disease severity in children with A-T.<br/>A total of 15 children with A-T and 15 age- and sex-matched controls wore a sensor with a triaxial accelerometer on their dominant wrist for 1 week at home. Activity intensity measures, derived from the sensor data, were compared with in-person neurological evaluation on the Brief Ataxia Rating Scale (BARS) and performance on a validated computer mouse task.<br/>Children with A-T were inactive the same proportion of each day as controls but produced more low intensity movements (p < 0.01; Cohen's d = 1.48) and fewer high intensity movements (p < 0.001; Cohen's d = 1.71). The range of activity intensities was markedly reduced in A-T compared to controls (p < 0.0001; Cohen's d = 2.72). The activity metrics correlated strongly with arm, gait, and total clinical severity (r: 0.71–0.87; p < 0.0001), correlated with specific computer task motor features (r: 0.67–0.92; p < 0.01), demonstrated high reliability (r: 0.86–0.93; p < 0.00001), and were not significantly influenced by age in the healthy control group.<br/>Motor activity metrics from a single, inexpensive wrist sensor during free-living behavior provide accurate and reliable information about diagnosis, neurological disease severity, and motor performance. These low-burden measurements are applicable independent of ambulatory status and are potential digital behavioral biomarkers in A-T.},

  pubtype = {journal},
  publisherversion = {https://doi.org/10.1007/s12311-021-01306-y},
}

@article{brody2021outcomes,
  title={Outcomes from Returning Individual versus Only Study-Wide Biomonitoring Results in an Environmental Exposure Study Using the Digital Exposure Report-Back Interface ({DERBI})},
  author={Brody, Julia Green and Cirillo, Piera M and Boronow, Katherine E and Havas, Laurie and Plumb, Marj and Susmann, Herbert P and Gajos, Krzysztof Z and Cohn, Barbara A},
  journal={Environmental health perspectives},
  volume={129},
  number={11},
  pages={117005},
  year={2021},
  url={https://doi.org/10.1289/EHP9072},
  abstract = {<b>Backtround:</b> Study participants want to receive their biomonitoring results for environmental chemicals, and ethics guidelines encourage reporting back. However, few studies have quantitively assessed participants’ responses to individual exposure reports, and digital methods have not been evaluated.<br/>
<b>Objectives:</b>
We isolated effects of receiving personal results vs. only study-wide findings and investigated whether effects differed for Black participants.<br/>
<b>Methods:</b>
We randomly assigned a subset of 295 women from the Child Health and Development Studies, half of whom were Black, to receive a report with personal environmental chemical results or only study-wide (aggregate) findings. Reports included results for 42 chemicals and lipids and were prepared using the Digital Exposure Report-Back Interface (DERBI). Women were interviewed before and after viewing their report. We analyzed differences in website activity, emotional responses, and intentions to participate in future research by report type and race using Wilcoxon rank sum tests, Wilcoxon-Pratt signed ranks tests, and multiple regression.<br/>
<b>Results:</b>
The personal report group spent approximately twice as much time on their reports as the aggregate group before the post-report-back interview. Among personal-report participants (n=93), 84\% (78) viewed chemical group information for at least one personal result highlighted on their home page; among aggregate-report participants (n=94), 66\% (62) viewed any chemical group page. Both groups reported strong positive feelings (curious, informed, interested, respected) about receiving results before and after report-back and mild negative feelings (helpless, scared, worried). Although most participants remained unworried after report-back, worry increased by a small amount in both groups. Among Black participants, higher post report-back worry was associated with having high levels of chemicals.<br/>
<b>Conclusions:</b>
Participants were motivated by their personal results to access online information about chemical sources and potential health effects. Report-back was associated with a small increase in worry, which could motivate appropriate action. Personal report-back increased engagement with exposure reports among Black participants. },

  pubtype = {journal},
  publisherversion={https://doi.org/10.1289/EHP9072},
  image = {http://www.eecs.harvard.edu/~kgajos/papers/images/brody2021outcomes.png},
}

@article{bucinca2021trust,
author = {Bu\c{c}inca, Zana and Malaya, Maja Barbara and Gajos, Krzysztof Z.},
title = {To Trust or to Think: Cognitive Forcing Functions Can Reduce Overreliance on AI in AI-Assisted Decision-Making},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW1},
url = {https://doi.org/10.1145/3449287},
doi = {10.1145/3449287},
abstract = {People supported by AI-powered decision support tools frequently overrely on the AI:
they accept an AI's suggestion even when that suggestion is wrong. Adding explanations
to the AI decisions does not appear to reduce the overreliance and some studies suggest
that it might even increase it. Informed by the dual-process theory of cognition,
we posit that people rarely engage analytically with each individual AI recommendation
and explanation, and instead develop general heuristics about whether and when to
follow the AI suggestions. Building on prior research on medical decision-making,
we designed three cognitive forcing interventions to compel people to engage more
thoughtfully with the AI-generated explanations. We conducted an experiment (N=199),
in which we compared our three cognitive forcing designs to two simple explainable
AI approaches and to a no-AI baseline. The results demonstrate that cognitive forcing
significantly reduced overreliance compared to the simple explainable AI approaches.
However, there was a trade-off: people assigned the least favorable subjective ratings
to the designs that reduced the overreliance the most. To audit our work for intervention-generated
inequalities, we investigated whether our interventions benefited equally people with
different levels of Need for Cognition (i.e., motivation to engage in effortful mental
activities). Our results show that, on average, cognitive forcing interventions benefited
participants higher in Need for Cognition more. Our research suggests that human cognitive
motivation moderates the effectiveness of explainable AI solutions.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {188},
numpages = {21},
keywords = {trust, explanations, cognition, artificial intelligence},

pubtype = {journal},
pdf = {bucinca21trust.pdf},
publisherversion = {https://doi.org/10.1145/3449287},
}

@inproceedings{jacobs2021designing,
author = {Jacobs, Maia and He, Jeffrey and F. Pradier, Melanie and Lam, Barbara and Ahn, Andrew C. and McCoy, Thomas H. and Perlis, Roy H. and Doshi-Velez, Finale and Gajos, Krzysztof Z.},
title = {Designing AI for Trust and Collaboration in Time-Constrained Medical Decisions: A Sociotechnical Lens},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445385},
abstract = { Major depressive disorder is a debilitating disease affecting 264 million people
worldwide. While many antidepressant medications are available, few clinical guidelines
support choosing among them. Decision support tools (DSTs) embodying machine learning
models may help improve the treatment selection process, but often fail in clinical
practice due to poor system integration. We use an iterative, co-design process to
investigate clinicians’ perceptions of using DSTs in antidepressant treatment decisions.
We identify ways in which DSTs need to engage with the healthcare sociotechnical system,
including clinical processes, patient preferences, resource constraints, and domain
knowledge. Our results suggest that clinical DSTs should be designed as multi-user
systems that support patient-provider collaboration and offer on-demand explanations
that address discrepancies between predictions and current standards of care. Through
this work, we demonstrate how current trends in explainable AI may be inappropriate
for clinical environments and consider paths towards designing these tools for real-world
medical systems. },
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {659},
numpages = {14},

pubtype = {conference},
pdf = {jacobs21designing.pdf},
blogpost = {https://maia-jacobs.medium.com/designing-ai-for-trust-and-collaboration-in-time-constrained-medical-decisions-a-sociotechnical-793d6321e6fa},
image = {http://www.eecs.harvard.edu/~kgajos/papers/images/jacobs2021designing-thumb.png},
}


@inproceedings{lekschas2021ask, 
author = {Lekschas, Fritz and Ampanavos, Spyridon and Siangliulue, Pao and Pfister, Hanspeter and Gajos, Krzysztof Z.},
 title = {Ask Me or Tell Me? Enhancing the Effectiveness of Crowdsourced Design Feedback},
 year = {2021},
 isbn = {9781450380966},
 publisher = {Association for Computing Machinery},
 address = {New York, NY, USA},
 url = {https://doi.org/10.1145/3411764.3445507},
 abstract = { Crowdsourced design feedback systems are emerging resources for getting large amounts of feedback in a short period of time. Traditionally, the feedback comes in the form of a declarative statement, which often contains positive or negative sentiment. Prior research has shown that overly negative or positive sentiment can strongly influence the perceived usefulness and acceptance of feedback and, subsequently, lead to ineffective design revisions. To enhance the effectiveness of crowdsourced design feedback, we investigate a new approach for mitigating the effects of negative or positive feedback by combining open-ended and thought-provoking questions with declarative feedback statements. We conducted two user studies to assess the effects of question-based feedback on the sentiment and quality of design revisions in the context of graphic design. We found that crowdsourced question-based feedback contains more neutral sentiment than statement-based feedback. Moreover, we provide evidence that presenting feedback as questions followed by statements leads to better design revisions than question- or statement-based feedback alone.},
 booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
 articleno = {564},
 numpages = {12},

 pdf = {lekschas21ask.pdf},
pubtype = {conference},
image = {http://www.eecs.harvard.edu/~kgajos/papers/images/lekschas21ask-thumb.png},
resources = {Supplementary material},
resources-url = {http://www.eecs.harvard.edu/~kgajos/papers/2021/lekschas21ask-supplement.pdf}, 
 }


@article{jacobs2021how,
author = {Maia Jacobs and Melanie F. Pradier and Thomas H. McCoy Jr and Roy H. Perlis and Finale Doshi-Velez and Krzysztof Z. Gajos},
title = {How machine-learning recommendations influence clinician treatment selections: the example of antidepressant selection},
journal = {Translational Psychiatry},
year = {2021},
volume = {11},
abstract = {Decision support systems embodying machine learning models offer the promise of improved standard of care for major depressive disorder, but little is known about how clinicians' treatment decisions will be influenced by machine learning recommendations and explanations. We used a within-subject factorial experiment to present 220 clinicians with patient vignettes, each with or without a machine learning (ML) recommendation and one of multiple forms of explanation. We found that interacting with machine learning recommendations did not significantly improve clinicians' treatment selection accuracy, assessed as concordance with expert psychopharmacologist consensus, compared to baseline scenarios in which clinicians made treatment decisions independently. Interacting with incorrect recommendations paired with explanations that included limited but easily interpretable information did lead to a significant reduction in treatment selection accuracy compared to baseline questions. These results suggest that incorrect ML recommendations may adversely impact clinician treatment selections and that explanations are insufficient for addressing overreliance on imperfect ML algorithms. More generally, our findings challenge the common assumption that clinicians interacting with ML tools will perform better than either clinicians or ML algorithms individually.},
url = {https://doi.org/10.1038/s41398-021-01224-x},

publisherversion = {https://doi.org/10.1038/s41398-021-01224-x},
pubtype = {journal},
blogpost = {https://maia-jacobs.medium.com/how-machine-learning-recommendations-influence-clinician-treatment-selections-the-example-of-the-33ecf348aedb}
}

@inproceedings{hu20:improving,
author = {Hu, Jingmei and Joung, Jiwon and Jacobs, Maia and Gajos, Krzysztof Z. and Seltzer, Margo I.},
title = {Improving Data Scientist Efficiency with Provenance},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380366},
doi = {10.1145/3377811.3380366},
abstract = {Data scientists frequently analyze data by writing scripts. We conducted a contextual inquiry with interdisciplinary researchers, which revealed that parameter tuning is a highly iterative process and that debugging is time-consuming. As analysis scripts evolve and become more complex, analysts have difficulty conceptualizing their workflow. In particular, after editing a script, it becomes difficult to determine precisely which code blocks depend on the edit. Consequently, scientists frequently re-run entire scripts instead of re-running only the necessary parts. We present ProvBuild, a tool that leverages language-level provenance to streamline the debugging process by reducing programmer cognitive load and decreasing subsequent runtimes, leading to an overall reduction in elapsed debugging time. ProvBuild uses provenance to track dependencies in a script. When an analyst debugs a script, ProvBuild generates a simplifed script that contains only the information necessary to debug a particular problem. We demonstrate that debugging the simplified script lowers a programmer's cognitive load and permits faster re-execution when testing changes. The combination of reduced cognitive load and shorter runtime reduces the time necessary to debug a script. We quantitatively and qualitatively show that even though ProvBuild introduces overhead during a script's first execution, it is a more efficient way for users to debug and tune complex workflows. ProvBuild demonstrates a novel use of language-level provenance, in which it is used to proactively improve programmer productively rather than merely providing a way to retroactively gain insight into a body of code.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {1086--1097},
numpages = {12},
keywords = {data analysis, provenance, incremental execution, dependency tracking},
location = {Seoul, South Korea},
series = {ICSE '20},

pdf = {hu20improving.pdf},
pubtype = {conference},
publisherversion = {https://doi.org/10.1145/3377811.3380366},
}   

@inproceedings{arnold20:predictcive,
author = {Arnold, Kenneth C. and Chauncey, Krysta and Gajos, Krzysztof Z.},
title = {Predictive Text Encourages Predictable Writing},
year = {2020},
isbn = {9781450371186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377325.3377523},
doi = {10.1145/3377325.3377523},
booktitle = {Proceedings of the 25th International Conference on Intelligent User Interfaces},
pages = {128-138},
numpages = {11},
keywords = {content effects of intelligent systems, predictive text},
location = {Cagliari, Italy},
series = {IUI '20},
abstract = {Intelligent text entry systems, including the now-ubiquitous predictive keyboard, can make text entry more efficient, but little is known about how these systems affect the content that people write. To study how predictive text systems affect content, we compared image captions written with different kinds of predictive text suggestions. Our key findings were that captions written with suggestions were shorter and that they included fewer words that that the system did not predict. Suggestions also boosted text entry speed, but with diminishing benefit for faster typists. Our findings imply that text entry systems should be evaluated not just by speed and accuracy but also by their effect on the content written.},

image={http://www.eecs.harvard.edu/~kgajos/papers/images/arnold20predictive.png},
pubtype = {conference},
pdf = {arnold20predictive.pdf},
publisherversion = {https://doi.org/10.1145/3377325.3377523},
blogpost = {https://medium.com/harvard-hci/predictive-text-systems-change-what-we-write-5eb75dc9fb0d},
}

@inproceedings{bucinca20:proxy,
author = {Bu\c{c}inca, Zana and Lin, Phoebe and Gajos, Krzysztof Z. and Glassman, Elena L.},
title = {Proxy Tasks and Subjective Measures Can Be Misleading in Evaluating Explainable AI Systems},
year = {2020},
isbn = {9781450371186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377325.3377498},
doi = {10.1145/3377325.3377498},
booktitle = {Proceedings of the 25th International Conference on Intelligent User Interfaces},
pages = {454-464},
numpages = {11},
keywords = {explanations, artificial intelligence, trust},
location = {Cagliari, Italy},
series = {IUI '20},
abstract = {Explainable artificially intelligent (XAI) systems form part of <i> sociotechnical systems, </i> e.g., human+AI teams tasked with making decisions. Yet, current XAI systems are rarely evaluated by measuring the performance of human+AI teams on actual decision-making tasks. We conducted two online experiments and one in-person think-aloud study to evaluate two currently common techniques for evaluating XAI systems: (1) using proxy, artificial tasks such as how well humans predict the AI's decision from the given explanations, and (2) using subjective measures of trust and preference as predictors of actual performance. The results of our experiments demonstrate that evaluations with proxy tasks did not predict the results of the evaluations with the actual decision-making tasks. Further, the subjective measures on evaluations with actual decision-making tasks did not predict the objective performance on those same tasks. Our results suggest that by employing misleading evaluation methods, our field may be inadvertently slowing its progress toward developing human+AI teams that can reliably perform better than humans or AIs alone.},

pubtype = {conference},
image = {http://www.eecs.harvard.edu/~kgajos/papers/images/bucinca20proxy.png},
pdf = {bucinca20proxy.pdf},
publisherversion = {https://doi.org/10.1145/3377325.3377498},
award = {Best Paper Award},
blogpost = {https://medium.com/harvard-hci/proxy-tasks-and-subjective-measures-can-be-misleading-in-evaluating-explainable-ai-systems-db8d5477cb85},
}

@article{huber20:conducting,
    author = {Huber, Bernd AND Gajos, Krzysztof Z.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Conducting online virtual environment experiments with uncompensated, unsupervised samples},
    year = {2020},
    month = {01},
    volume = {15},
    url = {https://doi.org/10.1371/journal.pone.0227629},
    pages = {1--17},
    abstract = {Web-based experimentation with uncompensated and unsupervised samples allows for a larger and more diverse sample population, more generalizable results, and faster theory to experiment cycle. Given that participants are unsupervised, it is still unknown whether the data collected in such settings would be of sufficiently high quality to support robust conclusions. Therefore, we investigated the feasibility of conducting such experiments online using virtual environment technologies. We conducted a conceptual replication of two prior experiments that have been conducted in virtual environments. Our results replicate findings previously obtained in conventional laboratory settings. These results hold across different device types of participants (ranging from desktop, through mobile devices to immersive virtual reality headsets), suggesting that experiments can be conducted online with uncompensated samples in virtual environments.},
    number = {1},
    doi = {10.1371/journal.pone.0227629},

pubtype={journal},
resources = {Data},
resources-url = {https://doi.org/10.7910/DVN/TYKHYD},
publisherversion={https://doi.org/10.1371/journal.pone.0227629},
image={http://www.eecs.harvard.edu/~kgajos/papers/images/huber20conducting-800.png},
}

@article{fischer20:visualization,
  title={Visualization of Electronic Health Record Data for Decision-Making in Diabetes and Congestive Heart Failure},
  author={Fischer, Shira H and Safran, Charles and Gajos, Krzysztof Z and Wright, Adam},
  journal={ACI Open},
  volume={4},
  number={01},
  pages={e35--e43},
  year={2020},
  publisher={Georg Thieme Verlag KG},
  url={https://doi.org/10.1055/s-0040-1702213},
  abstract={Objective:<br/> The aim of this study is to study the impact of graphical representation of health record data on physician decision-making to inform the design of health information technology.
<br/><br/>Materials and Methods:<br/> We conducted a within participants crossover design study using a simulated electronic health record (EHR) in which we presented cases with and without visualized data designed to highlight important clinical trends or relationships, followed by assessment of the impact on decision-making about next steps for patients with chronic diseases. We then asked whether trends were observed and about usability and satisfaction using validated usability questions and asked open-ended questions as well. Time to answer questions was also collected.
<br/><br/>Results:<br/> Twenty-one primary care providers participated in the study, including five for testing only and sixteen for the full study. Questions about clinical assessment or next actions were answered correctly 55% of the time. Regarding objective trends in the data, participants described noticing the trends 85% of the time. Differences in noticing trends or difficulty level of questions were not statistically significant. Satisfaction with the tool was high and participants agreed strongly that it helped them make better decisions without adding to the time it took.
<br/><br/>Discussion:<br/> The simulation allowed us to test the impact of a visualization on clinician practice in a realistic setting. Designers of EHRs should consider the ways information presentation can affect decision-making.
<br/><br/>Conclusion:<br/> Testing visualization tools can be done in a clinically realistic context. Providers desire visualizations and believe that they help them make better and faster decisions.},

  pubtype={journal},
  pdf={fischer20visualization.pdf},
  publisherversion={https://doi.org/10.1055/s-0040-1702213},
}

@article{gajos20:computer,
title={Computer Mouse Use Captures Ataxia and Parkinsonism, Enabling Accurate Measurement and Detection},
author={Krzysztof Z. Gajos and Katharina Reinecke and Mary Donovan and Christopher D. Stephen and  Albert Y. Hung and  Jeremy D. Schmahmann and  Anoopum S. Gupta},
journal={Movement Disorders},
year={2020},
month={February},
issue={2},
volume={35},
pages={354--358},
url={https://doi.org/10.1002/mds.27915},
abstract={Background:<br/>
Objective assessments of movement impairment are needed to support clinical trials and facilitate diagnosis. The objective of the current study was to determine if a rapid web‐based computer mouse test (Hevelius) could detect and accurately measure ataxia and parkinsonism.
<br/><br/>
Methods:<br/>
Ninety‐five ataxia, 46 parkinsonism, and 29 control participants and 229,017 online participants completed Hevelius. We trained machine‐learning models on age‐normalized Hevelius features to (1) measure severity and disease progression and (2) distinguish phenotypes from controls and from each other.
<br/><br/>
Results:<br/>
Regression model estimates correlated strongly with clinical scores (from r = 0.66 for UPDRS dominant arm total to r = 0.83 for the Brief Ataxia Rating Scale). A disease change model identified ataxia progression with high sensitivity. Classification models distinguished ataxia or parkinsonism from healthy controls with high sensitivity (≥0.91) and specificity (≥0.90).
<br/><br/>
Conclusions:<br/>
Hevelius produces a granular and accurate motor assessment in a few minutes of mouse use and may be useful as an outcome measure and screening tool.},

pdf={gajos19computer.pdf},
publisherversion={https://doi.org/10.1002/mds.27915},
image={http://www.eecs.harvard.edu/~kgajos/papers/images/hevelius.png},
pubtype={journal},
}

@article{jacobs19:think,
 author = {Jacobs, Maia and Gheihman, Galina and Gajos, Krzysztof Z. and Gupta, Anoopum S.},
 title = {"I Think We Know More Than Our Doctors": How Primary Caregivers Manage Care Teams with Limited Disease-related Expertise},
 journal = {Proc. ACM Hum.-Comput. Interact.},
 issue_date = {November 2019},
 volume = {3},
 number = {CSCW},
 month = nov,
 year = {2019},
 issn = {2573-0142},
 pages = {159:1--159:22},
 articleno = {159},
 numpages = {22},
 url = {http://doi.acm.org/10.1145/3359261},
 doi = {10.1145/3359261},
 acmid = {3359261},
 publisher = {ACM},
 address = {New York, NY, USA},
abstract = {Current models of patient-provider relationships in chronic disease management assume that healthcare providers possess expertise in the patient's diagnosis and trajectory. When managing a rare disease, patients and caregivers often work with care teams who are unfamiliar with the disease or inexperienced in its treatment. A deeper understanding of these relationships is needed to identify opportunities for support under these circumstances. We conducted qualitative interviews with parental caregivers of children with a rare neurodegenerative disorder, ataxia-telangiectasia. We found that when working with care teams inexperienced with the disease, parents must take on additional responsibilities beyond daily health management, including educating their care teams, initiating changes to their child's healthcare, and preventing adverse clinical events. Online community support can serve as a valuable resource to support parents in assuming these responsibilities. However, the emotional consequences of participation and information overload have hindered parents' community engagement. Therefore, two important research agendas for supporting this community are through the development of tools that facilitate parents' care coordination roles and tools that increase access to online community support. },

pdf={jacobs19think.pdf},
publisherversion = {http://doi.acm.org/10.1145/3359261},
pubtype={conference},
blogpost={https://medium.com/acm-cscw/i-think-we-know-more-than-our-doctors-how-primary-caregivers-manage-care-teams-with-limited-57bfa3817bdd},
}
	
@article{huber19:automatically,
 author = {Huber, Bernd and Shieber, Stuart and Gajos, Krzysztof Z.},
 title = {Automatically Analyzing Brainstorming Language Behavior with Meeter},
 journal = {Proc. ACM Hum.-Comput. Interact.},
 issue_date = {November 2019},
 volume = {3},
 number = {CSCW},
 month = nov,
 year = {2019},
 issn = {2573-0142},
 pages = {30:1--30:17},
 articleno = {30},
 numpages = {17},
 url = {http://doi.acm.org/10.1145/3359132},
 doi = {10.1145/3359132},
 acmid = {3359132},
 publisher = {ACM},
 address = {New York, NY, USA},
abstract = {Studying groups in such complex settings as group brainstorming would be much more informative if there were better tools to study them. Language both influences and indicates group behavior, and we need tools that let us study the content of what is communicated to understand how such dialogue acts as information sharing and shared understanding indicate group behavior. While one could annotate these spoken dialogue acts by hand, this is a tedious process that is not scalable. We present Meeter, a tool to more effectively study spoken group brainstorming interactions by automatically detecting information sharing, shared understanding, word counts, and group activation in spoken interactions. Our study shows that the measures computed by Meeter align with human-generated labels, and we present findings on the relationship between these measures and group outcomes, underlining the validity of the tool for studying groups. Our tool is valuable for researchers conducting group science, as well as designing groupware systems.},

pubtype={conference},
pdf={huber19automatically.pdf},
publisherversion = {http://doi.acm.org/10.1145/3359132},
image={http://www.eecs.harvard.edu/~kgajos/papers/images/meeter.png},
award = {Honorable Mention},
resources = {Code},
resources-url = {https://github.com/BerndHuber/meeter_code},
}

@inproceedings{jacobs19:integrating,
title={Integrating AI Recommendations into the Pharmacologic Management of Major Depressive Disorder},
author={Maia Jacobs and Roy H. Perlis and Melanie F. Pradier and Finale Doshi-Velez and Elizabeth Mynatt and Krzysztof Z. Gajos},
booktitle={Proceedings of the workshop on Identifying Challenges and Opportunities in Human–AI Collaboration in Healthcare at CSCW 2019},
year = {2019},
abstract = {AI predictions provide an important opportunity to support clinicians during complex decision-making processes. One such process is selecting treatments for major depressive disorder (MDD). Towards the goal of implementing AI models that make MDD treatment recommendations, we have designed a factorial vignette study to assess how recommendations and explanations may influence clinician's treatment decisions. We report on our initial data analysis, evaluating the influence of incorrect predictions on antidepressant selection. We found that recommendation correctness had a significant effect on treatment selection accuracy.},

pdf={jacobs19integrating.pdf},
pubtype={workshop},
}

@inproceedings{han19:eabbit,
title = {Eabbit 1.0: New Environmental Analysis Software for Solar Energy Representation},
author = {Jung Min Han and Ali Malkawi and Krzysztof Z. Gajos},
booktitle = {Proceedings of Building Simulation},
year = {2019},
abstract = {Given the challenges to designing high-performance buildings, the use of Building Performance Simulation (BPS) tools during the early design phase is indispensable. There are many tools for evaluating solar impact on buildings, ranging from energy use to daylighting and renewable energy. However, no tool accurately reflects architects' needs; all lack clear communication and proper visualization methods. This research addressed energy consumption and production measures impacted by exposure to the sun. The goal was to create a new type of early design decision support tool that functioned without running BPS optimization and parametric simulations. This was accomplished by developing important solar algorithms that were then used in a new method of solar representation for building design. It is important that usability assessments of this type of tool be conducted, especially with regards to its ability to satisfy architects' needs during the design process. However, such research is not yet common in the field of BPS. Thus, in the present research, user experiments were conducted to evaluate the effectiveness of Eabbit 1.0's key interface. The results of these experiments illustrate the impact of the proposed method on annual heating and cooling consumption. The results show that tool will assist users in making significantly better decisions regarding the installation of photovoltaic panels and other issues related to solar energy.},

pubtype={conference},
pdf={han19eabbit.pdf},
publisherversion={http://www.ibpsa.org/proceedings/BS2019/BS2019_210273.pdf},
image={http://www.eecs.harvard.edu/~kgajos/papers/images/han19eabbit.png},
}

@article{amir19:personalized,
title = "Personalized change awareness: Reducing information overload in loosely-coupled teamwork",
journal = "Artificial Intelligence",
volume = "275",
pages = "204 - 233",
year = "2019",
issn = "0004-3702",
doi = "https://doi.org/10.1016/j.artint.2019.05.005",
url = "http://www.sciencedirect.com/science/article/pii/S000437021930133X",
author = "Ofra Amir and Barbara J. Grosz and Krzysztof Z. Gajos and Limor Gultchin",
keywords = "Information sharing, Teamwork Support",
abstract = "Complex tasks such as treating patients with chronic conditions and developing software products are typically accomplished by teams that collaborate over an extended time duration. To remain coordinated, team members need to be aware of others' activities if those activities are likely to affect their own actions. However, identifying such interactions and sharing information appropriately is challenging, especially when the activities of team members are loosely-coupled. In practice, team members often either lack important information about others' activities, or are overwhelmed by the need to review too much information. This paper presents Personalized Change Awareness, a new approach for supporting team coordination which aims to automatically identify and share the subset of information about others' activities that is most relevant to each of the team members. The paper formally defines the computational problem of information sharing in loosely-coupled teamwork, which underlies the personalized change awareness approach. It defines a new representation, Mutual Influence Potential Networks (MIP-Nets) and an algorithm, MIP-DOI, that uses this representation to determine the information that is most relevant to each team member. In contrast to existing information sharing algorithms in multi-agent teams, MIP-DOI does not assume the availability of a priori knowledge of a team's possible plans, because human teams rarely explicitly define detailed long-term plans in advance. We demonstrate the ability of MIP-DOI to identify relevant information using simulations of collaborative activities. We further evaluated the contribution of personalized change awareness to team performance in a controlled user study. To this end, we developed a personalized change awareness mechanism for collaborative writing, which used MIP-DOI to determine which changes to share with each author. This evaluation demonstrates that the Personalized Change Awareness approach resulted in higher productivity and lower perceived workload without any change in final quality compared to the currently prevalent approach of sharing all change information. Our results also demonstrate that merely reducing the amount of information shared with co-authors is not enough: sharing a random subset of changes resulted in significantly lower quality of work than sharing a personalized subset of changes.",

pubtype={journal},
pdf={amir19personalized.pdf},
image={http://www.eecs.harvard.edu/~kgajos/papers/images/mips.png},
publisherversion={https://doi.org/10.1016/j.artint.2019.05.005},
}

@inproceedings{huber19:specialtime,
 author = {Huber, Bernd and Davis,III, Richard F. and Cotter, Allison and Junkin, Emily and Yard, Mindy and Shieber, Stuart and Brestan-Knight, Elizabeth and Gajos, Krzysztof Z.},
 title = {SpecialTime: Automatically Detecting Dialogue Acts from Speech to Support Parent-Child Interaction Therapy},
 booktitle = {Proceedings of the 13th EAI International Conference on Pervasive Computing Technologies for Healthcare},
 series = {PervasiveHealth'19},
 year = {2019},
 isbn = {978-1-4503-6126-2},
 location = {Trento, Italy},
 pages = {139--148},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/3329189.3329203},
 doi = {10.1145/3329189.3329203},
 acmid = {3329203},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Feedback, Healthcare, Machine Learning, Parent-Child Interaction, Therapy},
abstract = {Parent-child interaction therapy (PCIT) helps parents improve the quality of interaction with children who have behavior problems. The therapy trains parents to use effective dialogue acts when interacting with their children. Besides weekly coaching by therapists, the therapy relies on deliberate practice of skills by parents in their homes. We developed SpecialTime, a system that provides parents engaged in PCIT with automatic, real-time feedback on their dialogue act use. To do this, we first created a dataset of 6,022 parent dialogue acts, annotated by experts with dialogue act labels that therapists use to code parent speech. We then developed an algorithm that classifies the dialogue acts into 8 classes with an overall accuracy of 78%. To test the system in an actual clinical setting, we conducted a one month pilot study with four parents currently in therapy. The results suggest that automatic feedback on spoken dialogue acts is possible in PCIT, and that parents find the automatic feedback useful.},

resources = {Data},
resources-url = {https://doi.org/10.7910/DVN/C5Z3SC},
image = {http://www.eecs.harvard.edu/~kgajos/papers/images/specialtime-1000.png},
pubtype={conference},
pdf={huber19specialtime.pdf},
publisherversion={https://doi.org/10.1145/3329189.3329203}
}

@inproceedings{kim19:dataselfie,
 author = {Kim, Nam Wook and Im, Hyejin and Henry Riche, Nathalie and Wang, Alicia and Gajos, Krzysztof and Pfister, Hanspeter},
 title = {DataSelfie: Empowering People to Design Personalized Visuals to Represent Their Data},
 booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '19},
 year = {2019},
 isbn = {978-1-4503-5970-2},
 location = {Glasgow, Scotland Uk},
 pages = {79:1--79:12},
 articleno = {79},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/3290605.3300309},
 doi = {10.1145/3290605.3300309},
 acmid = {3300309},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {data portraits, data selfies, personal visualization, personal informatics, self-tracking, visual vocabulary, visualization},
abstract = {Many personal informatics systems allow people to collect and manage personal data and reflect more deeply about themselves. However, these tools rarely offer ways to customize how the data is visualized. In this work, we investigate the question of how to enable people to determine the representation of their data. We analyzed the Dear Data project to gain insights into the design elements of personal visualizations. We developed DataSelfie, a novel system that allows individuals to gather personal data and design custom visuals to represent the collected data. We conducted a user study to evaluate the usability of the system as well as its potential for individual and collaborative sensemaking of the data.},

image = {http://www.eecs.harvard.edu/~kgajos/papers/images/kim19dataselfie.png},
pubtype={conference},
pdf={kim19dataselfie.pdf},
publisherversion={http://doi.acm.org/10.1145/3290605.3300309},
}


@inproceedings{li18vounteer,
 author = {Li, Qisheng and Gajos, Krzysztof Z. and Reinecke, Katharina},
 title = {Volunteer-Based Online Studies With Older Adults and People with Disabilities},
 booktitle = {Proceedings of the 20th International ACM SIGACCESS Conference on Computers and Accessibility},
 series = {ASSETS '18},
 year = {2018},
 isbn = {978-1-4503-5650-3},
 location = {Galway, Ireland},
 pages = {229--241},
 numpages = {13},
 url = {http://doi.acm.org/10.1145/3234695.3236360},
 doi = {10.1145/3234695.3236360},
 acmid = {3236360},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {elderly people, online experimentation, people with disabilities, volunteers},
abstract = {There are few large-scale empirical studies with people with disabilities or older adults, mainly because recruiting participants with specific characteristics is even harder than recruiting young and/or non-disabled populations. Analyzing four online experiments on LabintheWild with a total of 355,656 participants, we show that volunteer-based online experiments that provide personalized feedback attract large numbers of participants with diverse disabilities and ages and allow robust studies with these populations that replicate and extend the findings of prior laboratory studies. To find out what motivates people with disabilities to take part, we additionally analyzed participants' feedback and forum entries that discuss LabintheWild experiments. The results show that participants use the studies to diagnose themselves, compare their abilities to others, quantify potential impairments, self-experiment, and share their own stories - findings that we use to inform design guidelines for online experiment platforms that adequately support and engage people with disabilities.},

pubtype={conference},
pdf={li18volunteer.pdf},
publisherversion={http://doi.acm.org/10.1145/3234695.3236360},
}

@inproceedings{jayatilaka18:petals,
 author = {Jayatilaka, Lahiru and Sengeh, David M. and Herrmann, Charles and Bertuccelli, Luca and Antos, Dimitrios and Grosz, Barbara J. and Gajos, Krzysztof Z.},
 title = {PETALS: Improving Learning of Expert Skill in Humanitarian Demining},
 booktitle = {Proceedings of the 1st ACM SIGCAS Conference on Computing and Sustainable Societies},
 series = {COMPASS '18},
 year = {2018},
 isbn = {978-1-4503-5816-3},
 location = {Menlo Park and San Jose, CA, USA},
 pages = {33:1--33:11},
 articleno = {33},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/3209811.3209871},
 doi = {10.1145/3209811.3209871},
 acmid = {3209871},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {demining, explosives detection, training systems},
abstract={To become proficient at landmine detection, novice deminers need to master several kinds of skills: the proper physical operation of the metal detector, the interpretation of the metal detector auditory feedback, and the abstract skill of constructing and interpreting mental representations of the "metallic signatures" produced by the buried objects. This last skill is particularly useful for safely dealing with mines laid out in cluster configurations, where their metallic signatures overlap and thus a danger exists that a deminer might either miss some of the mines or incorrectly assess their exact positions. However, some novice deminers find it challenging to learn how to properly reason about metallic signatures. We have developed PETALS, a system that explicitly visualizes a trainee's metal detector operation history on a training task as well as the edge points of the metallic signatures that the trainee collected. PETALS enables instructors to supervise multiple trainees at a time, to assess their performance at a glance, and to provide immediate and specific feedback both on the correctness of their final judgements about the number and positions of landmines, and on the process through which they arrived at their conclusions. The results of our field evaluations at the Humanitarian Demining Training Center showed that both the instructors and the trainees found the system a valuable addition to the training course. The results of a controlled study demonstrated that trainees who had access to PETALS during training made significantly fewer errors (6% error rate) on relevant tasks during the final exam (which was conducted without PETALS) than trainees who did not have access to PETALS during training (those participants had a 21% error rate).},

pubtype={conference},
pdf={jayatilaka18petals.pdf},
publisherversion={http://doi.acm.org/10.1145/3209811.3209871},
image = {http://www.eecs.harvard.edu/~kgajos/papers/images/PETALS-600.png},
slides-original = {papers/2018/jayatilaka18petals-slides.key.zip},
slides-converted = {papers/2018/jayatilaka18petals-slides.pdf},
award = {Best Paper Award},
}

@inproceedings{arnold18:sentiment,
 author = {Arnold, Kenneth and Chauncey, Krysta and Gajos, Krzysztof},
 title = {Sentiment Bias in Predictive Text Recommendations Results in Biased Writing},
 booktitle = {Proceedings of Graphics Interface 2018},
 series = {GI 2018},
 year = {2018},
 isbn = {978-0-9947868-2-1},
 location = {Toronto, Ontario},
 pages = {33 -- 40},
 numpages = {8},
 doi = {10.20380/GI2018.05},
 publisher = {Canadian Human-Computer Communications Society / Soci{\'e}t{\'e} canadienne du dialogue humain-machine},
abstract={Prior research has demonstrated that intelligent systems make biased decisions because they are trained on biased data. As people increasingly leverage intelligent systems to enhance their productivity and creativity, could system biases affect what people create? We demonstrate that in at least one domain (writing restaurant reviews), biased system behavior leads to biased human behavior: People presented with phrasal text entry shortcuts that were skewed positive wrote more positive reviews than they did when presented with negative-skewed shortcuts. This result contributes to the pertinent debate about the role of intelligent systems in our society.},

pubtype={conference},
pdf={arnold18sentiment.pdf},
publisherversion = {https://doi.org/10.20380/GI2018.07},
}

@ARTICLE{moyne18:development, 
author={M. M. Moyne and M. Herman and K. Z. Gajos and C. J. Walsh and D. P. Holland}, 
journal={IEEE Transactions on Learning Technologies}, 
title={The Development and Evaluation of DEFT, a Web-Based Tool for Engineering Design Education}, 
year={2018}, 
volume={11}, 
number={4}, 
pages={545-550}, 
abstract={This article describes the development of the Design Evaluation and Feedback Tool (DEFT), a custom-built web-based system that collects and reports data to support teaching, learning, and research in project-based engineering design education. The DEFT system collects data through short weekly questionnaires for students and instructors in engineering design classes, and uses these data to produce weekly reports for both types of user. The system is intended to engage students in reflective reporting on their experiential learning, to support educators in coaching student designers, and to serve as a data collection tool for education researchers. DEFT was developed through an iterative design and evaluation process, involving 185 students and 18 instructors at two universities. The system was evaluated using a combination of participation observation, user interviews, and anonymous questionnaires, and the results guided subsequent improvements to the system. This article describes the development and evaluation process, provides an overview of the resulting system, and ends by discussing the potential for DEFT to be used in evaluating and improving project-based design classes.}, 
keywords={Education;Data collection;Design methodology;Problem-solving;Feedback;Engineering design education;data collection tools;project-based learning}, 
doi={10.1109/TLT.2018.2810197}, 
ISSN={1939-1382}, 
month={Oct},

 pubtype = {journal},
 pdf = {moyne18development.pdf},
 publisherversion = {https://doi.org/10.1109/TLT.2018.2810197},
}

@article{wobbrock18:ability,
 author = {Wobbrock, Jacob O. and Gajos, Krzysztof Z. and Kane, Shaun K. and Vanderheiden, Gregg C.},
 title = {Ability-based Design},
 journal = {Commun. ACM},
 issue_date = {June 2018},
 volume = {61},
 number = {6},
 month = {may},
 year = {2018},
 issn = {0001-0782},
 pages = {62--71},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/3148051},
 doi = {10.1145/3148051},
 acmid = {3148051},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract = {By focusing on users' abilities rather than disabilities, designers can create interactive systems better matched to those abilities.},

 pubtype = {journal},
 publisherversion = {http://doi.acm.org/10.1145/3148051},
 authorizer = {https://dl.acm.org/authorize?N658399},
}

@article{kim17:bubbleview,
 author = {Kim, Nam Wook and Bylinskii, Zoya and Borkin, Michelle A. and Gajos, Krzysztof Z. and Oliva, Aude and Durand, Fredo and Pfister, Hanspeter},
 title = {BubbleView: An Interface for Crowdsourcing Image Importance Maps and Tracking Visual Attention},
 journal = {ACM Trans. Comput.-Hum. Interact.},
 issue_date = {November 2017},
 volume = {24},
 number = {5},
 month = {November},
 year = {2017},
 issn = {1073-0516},
 pages = {36:1--36:40},
 articleno = {36},
 numpages = {40},
 url = {http://doi.acm.org/10.1145/3131275},
 doi = {10.1145/3131275},
 acmid = {3131275},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract = {In this article, we present BubbleView, an alternative methodology for eye tracking using discrete mouse clicks to measure which information people consciously choose to examine. BubbleView is a mouse-contingent, moving-window interface in which participants are presented with a series of blurred images and click to reveal "bubbles" -- small, circular areas of the image at original resolution, similar to having a confined area of focus like the eye fovea. Across 10 experiments with 28 different parameter combinations, we evaluated BubbleView on a variety of image types: information visualizations, natural images, static webpages, and graphic designs, and compared the clicks to eye fixations collected with eye-trackers in controlled lab settings. We found that BubbleView clicks can both (i) successfully approximate eye fixations on different images, and (ii) be used to rank image and design elements by importance. BubbleView is designed to collect clicks on static images, and works best for defined tasks such as describing the content of an information visualization or measuring image importance. BubbleView data is cleaner and more consistent than related methodologies that use continuous mouse movements. Our analyses validate the use of mouse-contingent, moving-window methodologies as approximating eye fixations for different image and task types.},

 pubtype = {journal},
 publisherversion = {https://doi.org/10.1145/3131275},
 pdf = {kim17bubbleview.pdf},
}

@phdthesis{siangliulue17:supporting, 
author = {Pao Siangliulue},
title = {Supporting Effective Collective Ideation at Scale},
year = {2017},
school = {Harvard University},
address = {Cambridge, MA, USA},
abstract = {<p>Online collective ideation platforms, such as OpenIDEO or Quirky, have demonstrated the potential of large-scale collective innovation in various domains. However, the users of these platforms face new challenges of leveraging collective contributions. The large number of collected ideas prevents users from making full use of these ideas. Finding inspirations from the ideas involves wading through a sea of possibly mundane and redundant ideas. Synthesizing a few solutions from these ideas takes a lot of time and e ort. I argue that leaving users to explore ideas in a haphazard manner is ine ective and can decrease the quality of people's creative output. Prior work in cognitive science and creativity research has also suggested that deliberate exploration of the solution space can improve users' creative output and experience.</p><p>I introduce the concept of an idea map, a computational model of the emerging solution space that enables deliberate exploration interactions: 1) presenting a set of ideas with a controlled level of diversity appropriate to the stage of the creative process and 2) presenting a summary view of the solution space. I describe two scalable crowdsourced methods for generating this computational model. The first method computes the model from responses from small micro-task questions. The second method takes an “integrated crowdsourcing” approach that computes the model from users' natural activities during idea generation. The evaluation of the derived models show that the idea maps from both approaches agree with human judgments of similarities among ideas. I show the application of the idea map concept through experiments and a system called IdeaHound. IdeaHound derives an idea map using the integrated crowdsourcing approach and uses the derived model to guide users' exploration of the solution space. The results of the experiments show that an idea map can inspire people to generate diverse ideas. The integrated activities that enable IdeaHound to collect similarity judgments do not deter users from generating ideas and provide enough information to generate a reliable idea map. I also present a study on the e ects of di erent timings of delivering example ideas on an individual's idea generation. The results demonstrate that an intelligent system can provide inspiration at the right moment by using a computational model that is aware of semantic relationships between ideas. Finally, I demonstrate how to use an idea map to support sensemaking during the solution synthesis and present an empirical study of the e ect of presenting a summary view of ideas on people's solution synthesis.</p>},

pdf={siangliulue17supporting.pdf},
pubtype = {thesis},
image={http://iis.seas.harvard.edu/projects/images/creativity2-400.png}
}

@inproceedings{chan17:semantically,
author = {Chan, Joel and Siangliulue, Pao and Qori McDonald, Denisa and Liu, Ruixue and Moradinezhad, Reza and Aman, Safa and Solovey, Erin T. and Gajos, Krzysztof Z. and Dow, Steven P.},
 title = {Semantically Far Inspirations Considered Harmful?: Accounting for Cognitive States in Collaborative Ideation},
 booktitle = {Proceedings of the 2017 ACM SIGCHI Conference on Creativity and Cognition},
 series = {C\&C '17},
 year = {2017},
 isbn = {978-1-4503-4403-6},
 location = {Singapore, Singapore},
 pages = {93--105},
 numpages = {13},
 url = {http://doi.acm.org/10.1145/3059454.3059455},
 doi = {10.1145/3059454.3059455},
 acmid = {3059455},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {brainstorming, collaborative ideation, creativity, creativity support tools, examples},
 abstract = {Collaborative ideation systems can help people generate more creative ideas by exposing them to ideas different from their own. However, there are competing theoretical views on whether and when such exposure is helpful. Associationist theory suggests that exposing ideators to ideas that are semantically far from their own maximizes novel combinations of ideas. In contrast, SIAM theory cautions that systems should offer far ideas only when ideators reach an impasse (a cognitive state in which they have exhausted ideas within a particular category), and offer near ideas during productive ideation (a cognitive state in which they are actively exploring ideas within a category), which maximizes exploration within categories. Our research compares these theoretical recommendations. In an online experiment, 245 participants generated ideas for a themed wedding; we detected and validated participants' cognitive states using a combination of behavioral and neuroimaging data. Receiving far ideas during productive ideation resulted in slower ideation and less within-category exploration, without significant benefits for novelty, compared to receiving no inspirations. Participants were also more likely to hit an impasse when receiving far ideas during productive ideation. These findings suggest that far inspirational ideas can harm creativity if received during productive ideation.},

pubtype = {conference},
pdf = {chan17semantically.pdf},
publisherversion = {http://doi.acm.org/10.1145/3059454.3059455},
slides-original = {papers/2017/chan17semantically-slides.key},
slides-converted = {papers/2017/chan17semantically-slides.pdf},
}

@inproceedings{burgermaster17:role,
 author = {Burgermaster, Marissa and Gajos, Krzysztof Z. and Davidson, Patricia and Mamykina, Lena},
 title = {The Role of Explanations in Casual Observational Learning About Nutrition},
 booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '17},
 year = {2017},
 isbn = {978-1-4503-4655-9},
 location = {Denver, Colorado, USA},
 pages = {4097--4145},
 numpages = {49},
 publisherversion = {http://doi.acm.org/10.1145/3025453.3025874},
 doi = {10.1145/3025453.3025874},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {casual learning, crowdsourcing, nutrition literacy, observational learning},
abstract = {The ubiquity of internet-based nutrition information sharing indicates an opportunity to use social computing platforms to promote nutrition literacy and healthy nutritional choices. We conducted a series of experiments with unpaid volunteers using an online Nutrition Knowledge Test. The test asked participants to examine pairs of photographed meals and identify meals higher in a specific macronutrient (e.g., carbohydrate). After each answer, participants received no feedback on the accuracy of their answers, viewed proportions of peers choosing each response, received correctness feedback from an expert dietitian with or without expert-generated explanations, or received correctness feedback with crowd-generated explanations. The results showed that neither viewing peer responses nor correctness feedback alone improved learning. However, correctness feedback with explanations (i.e., modeling) led to significant learning gains, with no significant difference between explanations generated by experts or peers. This suggests the importance of explanations in social computing-based casual learning about nutrition and the potential for scaling this approach via crowdsourcing. },

pubtype = {conference},
pdf = {burgermaster17role.pdf},
blogpost = {https://labinthewild.tumblr.com/post/158409055045/can-food-photos-and-online-quizzes-help-people},
image = {http://www.eecs.harvard.edu/~kgajos/papers/images/mealyzer-600.png},
pubtype = {conference},
}

@inproceedings{huber17:effect,
 author = {Huber, Bernd and Reinecke, Katharina and Gajos, Krzysztof Z.},
 title = {The Effect of Performance Feedback on Social Media Sharing at Volunteer-Based Online Experiment Platforms},
 booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '17},
 year = {2017},
 isbn = {978-1-4503-4655-9},
 location = {Denver, Colorado, USA},
 pages = {1882--1886},
 numpages = {5},
 publisherversion = {http://doi.acm.org/10.1145/3025453.3025553},
 doi = {10.1145/3025453.3025553},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {self-evaluation, social comparison, volunteer-based online experiments},
abstract = {As an alternative to online labor markets, several platforms recruit unpaid online volunteers to participate in behavioral experiments that provide personalized feedback. These platforms rely on word-of-mouth sharing by previous participants for recruitment of new participants. We analyzed the impact of performance feedback provided at the end of an experiment on 81,131 participants' sharing behavior. We show that higher performing participants share significantly more. We also show that self-verification has a moderating effect: people who expected to do poorly are not affected by a high score, but people who expected to do as well as others or better, are. In a second experiment, we evaluate three distinct social comparison designs for the presentation of the results. As expected, the design that most emphasized participants' relative success led to most sharing. Contrary to our expectations, people who expected to do poorly benefited from the most optimistic social comparison more than participants who expected to do better than others.},

pubtype = {conference},
resources = {Data},
resources-url = {http://iis.seas.harvard.edu/resources/#huber17effect},
pdf = {huber17effect.pdf},
}

@inproceedings{gajos17:personality,
 author = {Gajos, Krzysztof Z. and Chauncey, Krysta},
 title = {The Influence of Personality Traits and Cognitive Load on the Use of Adaptive User Interfaces},
 booktitle = {Proceedings of the 22Nd International Conference on Intelligent User Interfaces},
 series = {IUI '17},
 year = {2017},
 isbn = {978-1-4503-4348-0},
 location = {Limassol, Cyprus},
 pages = {301--306},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/3025171.3025192},
 doi = {10.1145/3025171.3025192},
 acmid = {3025192},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {adaptive user interfaces, cognitive load, extraversion, need for cognition},
abstract = {One of the problems adaptive interfaces must solve is the issue of stability---users must be able to complete a familiar task reliably.  Split Adaptive Interfaces, where a limited part of the screen contains copies of the interface elements predicted to be of immediate use, are one technique for resolving this difficulty.  While prior work demonstrated that Split Adaptive Interfaces improve performance on average, the results of our study demonstrate systematic individual differences in the utilization of the adaptive features, which correlate with the stable user traits of Need for Cognition and Extraversion.  Specifically, higher Need for Cognition (a willingness to undertake difficult mental activities) is correlated with increased utilization rates, while higher Extraversion (a general orientation towards seeking gratification from the external world) is negatively correlated with utilization rates.  Our results also demonstrate a significant negative correlation between cognitive load induced by a secondary task and the utilization of the adaptive features.  This effect, however, is very small (less than two percentage points). Together, these results provide additional evidence of the usefulness of the split adaptive interface approach and a negligible effect of additional cognitive load, but also demonstrate that the approach does not benefit all users equally.},

pdf = {gajos17personality.pdf},
publisherversion = {http://doi.acm.org/10.1145/3025171.3025192},
resources = {Data},
resources-url = {http://iis.seas.harvard.edu/resources/#gajos17personality},
image = {http://www.eecs.harvard.edu/~kgajos/papers/images/gajos17personality-600.png},
blogpost = {https://labinthewild.tumblr.com/post/155444239065/thinking-vs-clicking-in-modern-user-interfaces},
pubtype = {conference},
}

@inproceedings{booth17:piggybacking,
 author = {Booth, Serena and Tompkin, James and Pfister, Hanspeter and Waldo, Jim and Gajos, Krzysztof and Nagpal, Radhika},
 title = {Piggybacking Robots: Human-Robot Overtrust in University Dormitory Security},
 booktitle = {Proceedings of the 2017 ACM/IEEE International Conference on Human-Robot Interaction},
 series = {HRI '17},
 year = {2017},
 isbn = {978-1-4503-4336-7},
 location = {Vienna, Austria},
 pages = {426--434},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/2909824.3020211},
 doi = {10.1145/2909824.3020211},
 acmid = {3020211},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {overtrust, piggybacking, robotics, secure access, tailgating, trust},
abstract = {Can overtrust in robots compromise physical security? We conducted a series of experiments in which a robot positioned outside a secure-access student dormitory asked passersby to assist it to gain access. We found individual participants were comparably likely to assist the robot in exiting (40% assistance rate) as in entering (19%). When the robot was disguised as a food delivery agent for the fictional start-up Robot Grub, individuals were more likely to assist the robot in entering (76%). Groups of people were more likely than individuals to assist the robot in entering (71%). Lastly, we found participants who identified the robot as a bomb threat were just as likely to open the door (87%) as those who did not. Thus, we demonstrate that overtrust---the unfounded belief that the robot does not intend to deceive or carry risk---can represent a significant threat to physical security.},

pubtype = {conference},
image = {http://www.eecs.harvard.edu/~kgajos/papers/images/piggybackingRobots-600.png},
pdf = {booth17piggybacking.pdf},
publisherversion = {http://doi.acm.org/10.1145/2909824.3020211},
}

@inproceedings{oliveira17:labinthewild,
 author = {Oliveira, Nigini and Jun, Eunice and Croxson, Trevor and Gajos, Krzysztof Z. and Reinecke, Katharina},
 title = {LabintheWild: How to Design Uncompensated, Feedback-driven Online Experiments},
 booktitle = {Companion of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing},
 series = {CSCW '17 Companion},
 year = {2017},
 isbn = {978-1-4503-4688-7},
 location = {Portland, Oregon, USA},
 pages = {25--28},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/3022198.3023267},
 doi = {10.1145/3022198.3023267},
 acmid = {3023267},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={We present LabintheWild, an online experiment platform that provides participants with the opportunity to learn about themselves and compare themselves to others. In the past four years, LabintheWild has attracted approximately 3.5 million participants of diverse ages and education levels who came from more than 200 countries and regions. Leveraging our experience with LabintheWild, we show how researchers can design engaging and robust online experiments that provide personalized feedback. In particular, our interactive tutorial highlights challenges and best-practice guidelines for designing volunteer-based online experiments for diverse participant samples.},

 pubtype = {other},
 pdf={oliveira17labinthewild.pdf},
 publisherversion = {http://doi.acm.org/10.1145/3022198.3023267},
} 

@inproceedings{law17:crowdsourcing,
 author = {Law, Edith and Gajos, Krzysztof Z. and Wiggins, Andrea and Gray, Mary L. and Williams, Alex},
 title = {Crowdsourcing As a Tool for Research: Implications of Uncertainty},
 booktitle = {Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing},
 series = {CSCW '17},
 year = {2017},
 isbn = {978-1-4503-4335-0},
 location = {Portland, Oregon, USA},
 pages = {1544--1561},
 numpages = {18},
 url = {http://doi.acm.org/10.1145/2998181.2998197},
 doi = {10.1145/2998181.2998197},
 acmid = {2998197},
 publisher = {ACM},
 address = {New York, NY, USA},
abstract={Numerous crowdsourcing platforms are now available to support research as well as commercial goals. However, crowdsourcing is not yet widely adopted by researchers for generating, processing or analyzing research data. This study develops a deeper understanding of the circumstances under which crowdsourcing is a useful, feasible or desirable tool for research, as well as the factors that may influence researchers' decisions around adopting crowdsourcing technology. We conducted semi-structured interviews with 18 researchers in diverse disciplines, spanning the humanities and sciences, to illuminate how research norms and practitioners' dispositions were related to uncertainties around research processes, data, knowledge, delegation and quality. The paper concludes with a discussion of the design implications for future crowdsourcing systems to support research.},

pubtype = {conference},
image = {http://iis.seas.harvard.edu/projects/images/crowdsourcing4research-600.png},
pdf={law17-crowdsourcing.pdf},
publisherversion={http://doi.acm.org/10.1145/2998181.2998197},
authorizer={http://dl.acm.org/authorize?N21369},
}

@article{boronow17:derbi,
	title = {{DERBI: A Digital Method to Help Researchers Offer ``Right-to-Know'' Personal Exposure Results}},
	author = {Katherine E. Boronow and Herbert P. Susmann and Krzysztof Z. Gajos and Ruthann A. Rudel and Kenneth C. Arnold and Phil Brown and Rachel Morello-Frosch and Laurie Havas and Julia Green Brody},
	year = {2017},
	month = {February},
	volume = {125},
	number = {2},
	journal = {Environmental Health Perspectives},
	abstract = {Researchers and clinicians in environmental health and medicine increasingly show respect for participants and patients by involving them in decision-making. In this context, the return of personal results to study participants is becoming ethical best practice, and many participants now expect to see their data. However, researchers often lack the time and expertise required for report-back, especially as studies measure greater numbers of analytes, including many without clear health guidelines. Our goal is to demonstrate how a prototype digital method, the Digital Exposure Report-Back Interface (DERBI), can reduce practical barriers to high-quality report-back. DERBI uses decision rules to automate the production of personalized summaries of notable results and generates individual results graphs with comparisons to the study group and benchmark populations. Reports discuss potential sources of chemical exposure, what is known and unknown about health effects, strategies for exposure reduction, and study-wide findings. Researcher tools promote discovery by drawing attention to patterns of high exposure and offer novel ways to increase participant engagement. DERBI reports have been field tested in two studies. Digital methods like DERBI reduce practical barriers to report-back, enabling researchers to meet their ethical obligations and participants to get knowledge they can use to make informed choices.},

	pubtype = {journal},
	url = {https://ehp.niehs.nih.gov/EHP702/},
	publisherversion = {https://ehp.niehs.nih.gov/EHP702/},
}

@phdthesis{amir16:intelligent, 
author = {Ofra Amir},
title = {Intelligent Information Sharing to Support Loosely-Coupled Teamwork},
year = {2016},
school = {Harvard University},
address = {Cambridge, MA, USA},
abstract = {<p>Complex tasks such as treating patients with complex medical conditions, conducting research, co-authoring documents and developing software products are typically accomplished by teams. Teamwork in such settings is often loosely-coupled as team members assume different responsibilities that match their individual expertise. This decomposition of activities enables team members to function autonomously and requires team members to be aware of others' actions only if these actions interact with their own activities. However, identifying interactions between collaborators' activities can be challenging. As a result, team members are often overwhelmed by too much irrelevant information about others' activities, or lack important relevant information, both of which can lead to coordination failures. This thesis argues that intelligent information sharing methods that identify the information that is most relevant to each team member can reduce coordination overhead and improve team performance.</p><p>Through a study of teams caring for children with complex medical conditions, this thesis characterizes the coordination challenges of loosely-coupled teams and formalizes the problem of information sharing in such teams. The thesis introduces Mutual Influence Potential Networks, a new representation for modeling collaborative activities. It further defines MIP-DOI, an algorithm which uses the Mutual Influence Potential Network representation to identify the most relevant information for each team member.</p><p>The thesis also presents the design, implementation and evaluation of a personalized change awareness mechanism, which uses MIP-DOI to reduce the amount of shared change information in the context of collaborative writing. The results of an experiment evaluating this mechanism show that compared to the currently most prevalent approach of presenting users with all changes made by their collaborators, the personalized change awareness mechanism resulted in significantly reduced perceived workload and significantly increased productivity of team members. Importantly, the personalized change awareness mechanism did not have any detrimental effect on the quality of the work.</p>},

pubtype = {thesis},
pdf={amir16intelligent.pdf},
}

@inproceedings{siangliulue16:ideahound-uist,
 author = {Siangliulue, Pao and Chan, Joel and Dow, Steven P. and Gajos, Krzysztof Z.},
 title = {IdeaHound: Improving Large-scale Collaborative Ideation with Crowd-Powered Real-time Semantic Modeling},
 booktitle = {Proceedings of the 29th Annual Symposium on User Interface Software and Technology},
 series = {UIST '16},
 year = {2016},
 isbn = {978-1-4503-4189-9},
 location = {Tokyo, Japan},
 pages = {609--624},
 numpages = {16},
 url = {http://doi.acm.org/10.1145/2984511.2984578},
 doi = {10.1145/2984511.2984578},
 acmid = {2984578},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {collaborative innovation, idea generation},
 abstract = {Prior work on creativity support tools demonstrates how a computational semantic model of a solution space can enable interventions that substantially improve the number, quality and diversity of ideas. However, automated semantic modeling often falls short when people contribute short text snippets or sketches. Innovation platforms can employ humans to provide semantic judgments to construct a semantic model, but this relies on external workers completing a large number of tedious micro tasks. This requirement threatens both accuracy (external workers may lack expertise and context to make accurate semantic judgments) and scalability (external workers are costly). In this paper, we introduce IdeaHound, an ideation system that seamlessly integrates the task of defining semantic relationships among ideas into the primary task of idea generation. The system combines implicit human actions with machine learning to create a computational semantic model of the emerging solution space. The integrated nature of these judgments allows IdeaHound to leverage the expertise and efforts of participants who are already motivated to contribute to idea generation, overcoming the issues of scalability inherent to existing approaches. Our results show that participants were equally willing to use (and just as productive using) IdeaHound compared to a conventional platform that did not require organizing ideas. Our integrated crowdsourcing approach also creates a more accurate semantic model than an existing crowdsourced approach (performed by external crowds). We demonstrate how this model enables helpful creative interventions: providing diverse inspirational examples, providing similar ideas for a given idea and providing a visual overview of the solution space.},

 pubtype = {conference},
pdf = {siangliulue16ideahound-uist.pdf},
image={http://www.eecs.harvard.edu/~kgajos/papers/images/ideaHound-computationalModel.png},
publisherversion={http://dx.doi.org/10.1145/2984511.2984578},
mendeley={https://www.mendeley.com/catalog/ideahound-improving-largescale-collaborative-ideation-crowdpowered-realtime-semantic-modeling/},
}

@inproceedings{arnold16:suggesting,
 author = {Arnold, Kenneth C. and Gajos, Krzysztof Z. and Kalai, Adam T.},
 title = {On Suggesting Phrases vs. Predicting Words for Mobile Text Composition},
 booktitle = {Proceedings of the 29th Annual Symposium on User Interface Software and Technology},
 series = {UIST '16},
 year = {2016},
 isbn = {978-1-4503-4189-9},
 location = {Tokyo, Japan},
 pages = {603--608},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2984511.2984584},
 doi = {10.1145/2984511.2984584},
 acmid = {2984584},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {mobile text composition, phrase suggestions},
abstract = {A system capable of suggesting multi-word phrases while someone is writing could supply ideas about content and phrasing and allow those ideas to be inserted efficiently. Meanwhile, statistical language modeling has provided various approaches to predicting phrases that users type. We introduce a simple extension to the familiar mobile keyboard suggestion interface that presents phrase suggestions that can be accepted by a repeated-tap gesture. In an extended composition task, we found that phrases were interpreted as suggestions that affected the content of what participants wrote more than conventional single-word suggestions, which were interpreted as predictions. We highlight a design challenge: how can a phrase suggestion system make valuable suggestions rather than just accurate predictions?},

pubtype = {conference},
pdf = {arnold16suggesting.pdf},
publisherversion = {http://dx.doi.org/10.1145/2984511.2984584},
}

@inproceedings{kim16:acceptance,
author = {Kim, Sunyoung and Gajos, Krzysztof Z. and Muller, Michael and Grosz, Barbara J.},
 title = {Acceptance of Mobile Technology by Older Adults: A Preliminary Study},
 booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services},
 series = {MobileHCI '16},
 year = {2016},
 isbn = {978-1-4503-4408-1},
 location = {Florence, Italy},
 pages = {147--157},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/2935334.2935380},
 doi = {10.1145/2935334.2935380},
 acmid = {2935380},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {aging, digital health, healthcare technology, mobile technology adoption, older adults},
abstract = {Mobile technologies offer the potential for enhanced healthcare, especially by supporting self-management of chronic care. For these technologies to impact chronic care, they need to work for older adults, because the majority of people with chronic conditions are older. A major challenge remains: integrating the appropriate use of such technologies into the lives of older adults. We investigated how older adults would accept mobile technologies by interviewing two groups of older adults (technology adopters and non-adopters who aged 60+) about their experiences and perspectives to mobile technologies. Our preliminary results indicate that there is an additional phase, the intention to learn, and three relating factors, self-efficacy, conversion readiness, and peer support, that significantly influence the acceptance of mobile technologies among the participants, but are not represented in the existing models. With these findings, we propose a tentative theoretical model that extends the existing theories to explain the ways in which our participants came to accept mobile technologies. Future work should investigate the validity of the proposed model by testing our findings against younger people.},

pubtype = {conference},
pdf = {skim16acceptance.pdf},
publisherversion = {http://doi.acm.org/10.1145/2935334.2935380},
}

@inproceedings{amir16:mutual,
author = {Ofra Amir and Barbara Grosz and Krzysztof Z. Gajos},
title = {Mutual Influence Potential Networks: Enabling Information Sharing in Loosely-Coupled Extended-Duration Teamwork},
booktitle = {Proceedings of IJCAI'16},
year = 2016,
abstract = {Complex collaborative activities such as treating patients, co-authoring documents and developing software are often characterized by teamwork that is loosely coupled and extends in time. To remain coordinated and avoid conflicts, team members need to identify dependencies between their activities - which though loosely coupled may interact - and share information appropriately. The loose-coupling of tasks increases the difficulty of identifying dependencies, with the result that team members often lack important information or are overwhelmed by irrelevant information. This paper formalizes a new multi-agent systems problem, Information Sharing in Loosely-Coupled Extended-Duration Teamwork (ISLET). It defines a new representation, Mutual Influence Potential Networks (MIP-Nets) and an algorithm, MIP-DOI, that uses this representation to determine the information that is most relevant to each team member. Importantly, because the extended duration of the teamwork precludes team members developing complete plans in advance, the MIP-Nets approach, unlike prior work on information sharing, does not rely on a priori knowledge of a team's possible plans. Instead, it models collaboration patterns and dependencies among people and their activities based on team-members' interactions. Empirical evaluations show that this approach is able to learn collaboration patterns and identify relevant information to share with team members.},

pubtype = {conference},
pdf = {amir16mutual.pdf},
}

@inproceedings{mamykina16:learning,
 author = {Mamykina, Lena and Smyth, Thomas N. and Dimond, Jill P. and Gajos, Krzysztof Z.},
 title = {Learning From the Crowd: Observational Learning in Crowdsourcing Communities},
 booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '16},
 year = {2016},
 isbn = {978-1-4503-3362-7},
 location = {Santa Clara, California, USA},
 pages = {2635--2644},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2858036.2858560},
 doi = {10.1145/2858036.2858560},
 acmid = {2858560},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {crowdsourcing, nutritional assessment, observational learning},
abstract = {Crowd work provides solutions to complex problems effectively, efficiently, and at low cost. Previous research showed that feedback, particularly correctness feedback can help crowd workers improve their performance; yet such feedback, particularly when generated by experts, is costly and difficult to scale. In our research we investigate approaches to facilitating continuous observational learning in crowdsourcing communities. In a study conducted with workers on Amazon Mechanical Turk, we asked workers to complete a set of tasks identifying nutritional composition of different meals. We examined workers' accuracy gains after being exposed to expert-generated feedback and to two types of peer-generated feedback: direct accuracy assessment with explanations of errors, and a comparison with solutions generated by other workers. The study further confirmed that expert-generated feedback is a powerful mechanism for facilitating learning and leads to significant gains in accuracy. However, the study also showed that comparing one's own solutions with a variety of solutions suggested by others and their comparative frequencies leads to significant gains in accuracy. This solution is particularly attractive because of its low cost, minimal impact on time and cost of job completion, and high potential for adoption by a variety of crowdsourcing platforms.},

pubtype = {conference},
pdf = {mamykina16learning.pdf},
publisherversion = {http://dx.doi.org/10.1145/2858036.2858560},
}

@inproceedings{zhou16:ingenium,
 author = {Zhou, Sharon and Livingston, Ivy J. and Schiefsky, Mark and Shieber, Stuart M. and Gajos, Krzysztof Z.},
 title = {Ingenium: Engaging Novice Students with Latin Grammar},
 booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '16},
 year = {2016},
 isbn = {978-1-4503-3362-7},
 location = {Santa Clara, California, USA},
 pages = {944--956},
 numpages = {13},
 url = {http://doi.acm.org/10.1145/2858036.2858239},
 doi = {10.1145/2858036.2858239},
 acmid = {2858239},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Latin education, engagement, grammar},
abstract = {Reading Latin poses many difficulties for English speakers, because they are accustomed to relying on word order to determine the roles of words in a sentence. In Latin, the grammatical form of a word, and not its position, is responsible for determining the word's function in a sentence. It has proven challenging to develop pedagogical techniques that successfully draw students' attention to the grammar of Latin and that students find engaging enough to use. Building on some of the most promising prior work in Latin instruction--the Michigan Latin approach--and on the insights underlying block-based programming languages used to teach children the basics of computer science, we developed Ingenium. Ingenium uses abstract puzzle blocks to communicate grammatical concepts. Engaging students in grammatical reflection, Ingenium succeeds when students are able to effectively decipher the meaning of Latin sentences. We adapted Ingenium to be used for two standard classroom activities: sentence translations and fill-in-the-blank exercises. We evaluated Ingenium with 67 novice Latin students in universities across the United States. When using Ingenium, participants opted to perform more optional exercises, completed translation exercises with significantly fewer errors related to word order and errors overall, as well as reported higher levels of engagement and attention to grammar than when using a traditional text-based interface.},

video-embedded={<iframe width="854" height="480" src="https://www.youtube.com/embed/th3fobLzKUE" frameborder="0" allowfullscreen></iframe>},
pubtype = {conference},
pdf = {zhou16ingenium.pdf},
publisherversion = {http://dx.doi.org/10.1145/2858036.2858239},
}


@inproceedings{law16:curiosity,
 author = {Law, Edith and Yin, Ming and Goh, Joslin and Chen, Kevin and Terry, Michael A. and Gajos, Krzysztof Z.},
 title = {Curiosity Killed the Cat, but Makes Crowdwork Better},
 booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '16},
 year = {2016},
 isbn = {978-1-4503-3362-7},
 location = {Santa Clara, California, USA},
 pages = {4098--4110},
 numpages = {13},
 url = {http://doi.acm.org/10.1145/2858036.2858144},
 doi = {10.1145/2858036.2858144},
 acmid = {2858144},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {crowdsourcing, curiosity, motivation},
abstract = {Crowdsourcing systems are designed to elicit help from humans to accomplish tasks that are still difficult for computers. How to motivate workers to stay longer and/or perform better in crowdsourcing systems is a critical question for designers. Previous work have explored different motivational frameworks, both extrinsic and intrinsic. In this work, we examine the potential for curiosity as a new type of intrinsic motivational driver to incentivize crowd workers. We design crowdsourcing task interfaces that explicitly incorporate mechanisms to induce curiosity and conduct a set of experiments on Amazon's Mechanical Turk. Our experiment results show that curiosity interventions improve worker retention without degrading performance, and the magnitude of the effects are influenced by both the personal characteristics of the worker and the nature of the task.},

pubtype = {conference},
pdf = {law16curiosity.pdf},
publisherversion = {http://dx.doi.org/10.1145/2858036.2858144},
image = {http://iis.seas.harvard.edu/projects/images/curiosity-600.png},
award = {Honorable Mention},
}

@inproceedings{kim16:SwellFit,
  author = {Sunyoung Kim and Yasha Iravantchi and Krzysztof Z. Gajos and Barbara Grosz},
  title={SwellFit: a Wearable Sensor for Patients with Congestive Heart Failure},
  booktitle = {Proceedings of the Workshop on Interactive Systems in Healthcare (WISH) 2016},
  year = {2016},
  abstract = {Congestive heart failure (CHF) is the most common reason for hospitalization in people aged 65 years and older in the United States. Especially, a very high rate of unplanned readmissions within 30 days of discharge due to CHF occurs a heavy associated financial burden and degraded quality of care. To effectively prevent CHF readmission and improve overall care, this paper proposes SwellFit, a novel wearable sensor that helps outpatients to proactively monitor a physical symptom of worsening CHF, ankle swelling. Using a flex sensor, SwellFit monitors changes in ankle curvature as an indication of swelling. A pilot test with 4 adults showed that SwellFit successfully distinguish noise data and motion artifacts from ankle swelling. Collaborating with cardiac experts, we are currently planning to test SwellFit with hospitalized CHF patients who have swelling conditions to demonstrate the feasibility and reliability of SwellFit on detecting swelling from ankle curvature.},

pubtype = {workshop},
pdf = {skim16swellfit.pdf},
}

@inproceedings{siangliulue16:ideahound,
 author = {Siangliulue, Pao and Chan, Joel and Huber, Bernd and Dow, Steven P. and Gajos, Krzysztof Z.},
 title = {IdeaHound: Self-sustainable Idea Generation in Creative Online Communities},
 booktitle = {Proceedings of the 19th ACM Conference on Computer Supported Cooperative Work and Social Computing Companion},
 series = {CSCW '16 Companion},
 year = {2016},
 isbn = {978-1-4503-3950-6},
 location = {San Francisco, California, USA},
 pages = {98--101},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/2818052.2874335},
 doi = {10.1145/2818052.2874335},
 acmid = {2874335},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {collaborative idea generation, creativity support tool},
 abstract = {One main challenge in large creative online communities is helping their members find inspirational ideas from a large pool of ideas. A high-level approach to address this challenge is to create a synthesis of emerging solution space that can be used to provide participants with creative and diverse inspirational ideas of others. Existing approaches to generate the synthesis of solution space either require community members to engage in tasks that detract from the main activity of generating ideas or depend on external crowd workers to help organize the ideas. We built IdeaHound a collaborative idea generation system that demonstrates an alternative "organic" human computation approach, where community members (rather than external crowds) contribute feedback about ideas as a byproduct of an activity that naturally integrates into the ideation process. This feedback in turn helps the community identify diverse inspirational ideas that can prompt community members to generate more high-quality and diverse ideas.},

 pubtype = {poster},
 publisherversion = {http://dx.doi.org/10.1145/2818052.2874335},
} 

@inproceedings{huang16chordripple,
 author = {Huang, Cheng-Zhi Anna and Duvenaud, David and Gajos, Krzysztof Z.},
 title = {ChordRipple: Recommending Chords to Help Novice Composers Go Beyond the Ordinary},
 booktitle = {Proceedings of the 21st International Conference on Intelligent User Interfaces},
 series = {IUI '16},
 year = {2016},
 isbn = {978-1-4503-4137-0},
 location = {Sonoma, California, USA},
 pages = {241--250},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2856767.2856792},
 doi = {10.1145/2856767.2856792},
 acmid = {2856792},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {chords, creativity support tools, recommender systems, neural language models, embeddings, harmony, music, songwriting},
abstract = {Novice composers often find it difficult to go beyond common chord progressions. To make it easier for composers to experiment with radical chord choices, we built a creativity support tool, CHORDRIPPLE, which makes chord recommendations that aim to be both diverse and appropriate to the current context. Composers can use it to help select the next chord, or to replace sequences of chords in an internally consistent manner.
To make such recommendations, we adapt a neural network model from natural language processing known as WORD2VEC to the music domain. This model learns chord embeddings from a corpus of chord sequences, placing chords nearby when they are used in similar contexts. The learned embeddings support creative substitutions between chords, and also exhibit topological properties that correspond to musical structure. For example, the major and minor chords are both arranged in the latent space in shapes corresponding to the circle-of-fifths.
Our structured observations with 14 music students show that the tool helped them explore a wider palette of chords, and to make "big jumps in just a few chords". It gave them "new ideas of ways to move forward in the piece", not just on a chord-to-chord level but also between phrases. Our controlled studies with 9 more music students show that more adventurous chords are adopted when composing with CHORDRIPPLE.},

pubtype = {conference},
pdf = {huang16chordripple.pdf},
publisherversion = {http://dx.doi.org/10.1145/2856767.2856792},
}

@inproceedings{williams16:axis,
 author = {Williams, Joseph Jay and Kim, Juho and Rafferty, Anna and Maldonado, Samuel and Gajos, Krzysztof Z. and Lasecki, Walter S. and Heffernan, Neil},
 title = {AXIS: Generating Explanations at Scale with Learnersourcing and Machine Learning},
 booktitle = {Proceedings of the Third (2016) ACM Conference on Learning @ Scale},
 series = {L@S '16},
 year = {2016},
 isbn = {978-1-4503-3726-7},
 location = {Edinburgh, Scotland, UK},
 pages = {379--388},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2876034.2876042},
 doi = {10.1145/2876034.2876042},
 acmid = {2876042},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {adaptive learning, crowdsourcing, explanation, learnersourcing, learning at scale, machine learning},
abstract = {While explanations may help people learn by providing information about why an answer is correct, many problems on online platforms lack high-quality explanations. This paper presents AXIS (Adaptive eXplanation Improvement System), a system for obtaining explanations. AXIS asks learners to generate, revise, and evaluate explanations as they solve a problem, and then uses machine learning to dynamically determine which explanation to present to a future learner, based on previous learners' collective input. Results from a case study deployment and a randomized experiment demonstrate that AXIS elicits and identifies explanations that learners find helpful. Providing explanations from AXIS also objectively enhanced learning, when compared to the default practice where learners solved problems and received answers without explanations. The rated quality and learning benefit of AXIS explanations did not differ from explanations generated by an experienced instructor.},

pubtype = {conference},
pdf = {williams16axis.pdf},
publisherversion = {http://dx.doi.org/10.1145/2876034.2876042},
award = {Honorable Mention},
}

@inproceedings{siangliulue15:supporting,
  Address = {New York, NY, USA},
  Author = {Siangliulue, Pao},
  Booktitle = {Adjunct Proceedings of the 28th Annual ACM Symposium on User Interface Software and Technology},
  Keywords = {creativity support system, ideation, collective intelligence},
  Location = {Charlotte, North Carolina, USA},
  Numpages = {4},
  Publisher = {ACM},
  Title = {Supporting Collaborative Innovation at Scale},
  Year = {2015},
abstract = {Emerging online innovation platforms have enabled large groups of people to collaborate and generate ideas together in ways that were not possible before. However, these platforms also introduce new challenges in finding inspiration from a large number of ideas, and coordinating the collective effort. In my dissertation, I address the challenges of large scale idea generation platforms by developing methods and systems for helping people make effective use of each other's ideas, and for orchestrating collective effort to reduce redundancy and increase the quality and breadth of generated ideas.},

 pdf = {siangliulue15uistdc.pdf},
  note = "To appear."
  }


@inproceedings{siangliulue15:providing,
 author = {Siangliulue, Pao and Chan, Joel and Gajos, Krzysztof Z. and Dow, Steven P.},
 title = {Providing Timely Examples Improves the Quantity and Quality of Generated Ideas},
 booktitle = {Proceedings of the 2015 ACM SIGCHI Conference on Creativity and Cognition},
 series = {C\&C '15},
 year = {2015},
 isbn = {978-1-4503-3598-0},
 location = {Glasgow, United Kingdom},
 pages = {83--92},
 numpages = {10},
 doi = {10.1145/2757226.2757230},
 acmid = {2757230},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {collective intelligence, creativity, examples, ideation},
abstract={Emerging online ideation platforms with thousands of example ideas provide an important resource for creative production. But how can ideators best use these examples to create new innovations? Recent work has suggested that not just the choice of examples, but also the timing of their delivery can impact creative outcomes. Building on existing cognitive theories of creative insight, we hypothesize that people are likely to benefit from examples when they run out of ideas. We explore two example delivery mechanisms that test this hypothesis: 1) a system that proactively provides examples when a user appears to have run out of ideas, and 2) a system that provides examples when a user explicitly requests them. Our online experiment (N=97) compared these two mechanisms against two baselines: providing no examples and automatically showing examples at a regular interval. Participants who requested examples themselves generated ideas that were rated the most novel by external evaluators. Participants who received ideas automatically when they appeared to be stuck produced the most ideas. Importantly, participants who received examples at a regular interval generated fewer ideas than participants who received no examples, suggesting that mere access to examples is not sufficient for creative inspiration. These results emphasize the importance of the timing of  example delivery. Insights from this study can inform the design of collective ideation support systems that help people generate many high quality ideas.},

pdf = {siangliulue15providing.pdf},
publisherversion = {http://dx.doi.org/10.1145/2757226.2757230},
pubtype = {conference},
}


@inproceedings{siangliulue15:intelligent,
 author = {Siangliulue, Pao},
 title = {Intelligent Systems to Support Large-Scale Collective Creative Idea Generation},
 booktitle = {Proceedings of the 2015 ACM SIGCHI Conference on Creativity and Cognition},
 series = {C\&C '15},
 year = {2015},
 isbn = {978-1-4503-3598-0},
 location = {Glasgow, United Kingdom},
 pages = {327--328},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2757226.2764764},
 doi = {10.1145/2757226.2764764},
 acmid = {2764764},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {collaborative idea generation, creativity},
 abstract = {In recent years, it has become possible for large groups of people to collaborate and generate ideas together in ways that were not possible before. However, the large number of ideas and participants in this setting also pose new challenges in helping people find inspiration from a large pool of ideas, and coordinating the collective effort. My research aims to address the challenges of large scale idea generation platforms by developing methods and systems for helping people make effective use of each other's ideas, and orchestrate collective effort to reduce redundancy and increase the breadth of generated ideas.},

 pdf = {siangliulue15ccdc.pdf},
  publisherversion = {http://doi.acm.org/10.1145/2757226.2764764},
  pubtype = {other},
} 

@misc{zhou15engineering,
author = {Sharon Zhou},
title = {Engineering Ingenium: Improving Engagement and Accuracy with the Visualization of Latin for Language Learning},
year = {2015},
howpublished = {Undergraduate Thesis},

pdf = {zhou15ingenium-thesis.pdf},
}

@inproceedings{amir15:care,
 author = {Amir, Ofra and Grosz, Barbara J. and Gajos, Krzysztof Z. and Swenson, Sonja M. and Sanders, Lee M.},
 title = {From Care Plans to Care Coordination: Opportunities for Computer Support of Teamwork in Complex Healthcare},
 booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
 series = {CHI '15},
 year = {2015},
 isbn = {978-1-4503-3145-6},
 location = {Seoul, Republic of Korea},
 pages = {1419--1428},
 numpages = {10},
 publisher = {ACM},
 address = {New York, NY, USA},
  abstract = {Children with complex health conditions require care from a large, diverse team of caregivers that includes multiple types of medical professionals, parents and community support organizations. Coordination of their outpatient care, essential for good outcomes, presents major challenges. Extensive healthcare research has shown that the use of integrated, team-based care plans improves care coordination, but such plans are rarely deployed in practice. This paper reports on a study of care teams treating children with complex conditions at a major university tertiary care center. This study investigated barriers to plan implementation and resultant care coordination problems. It revealed the complex nature of teamwork in complex care, which poses challenges to team coordination that extend beyond those identified in prior work and handled by existing coordination systems. The paper builds on a computational teamwork theory to identify opportunities for technology to support increased plan-based complex-care coordination and to propose design approaches for systems that enable and enhance such coordination.},

  pdf = {amir15care.pdf},
  slides-original = {papers/2015/amir15care-slides.pptx},
  slides-converted = {papers/2015/amir15care-slides.pdf},
  publisherversion = {http://doi.acm.org/10.1145/2702123.2702320},
  pubtype = {conference},
  award = {Honorable Mention},
}

@inproceedings{kim15bubble,
 author = {Kim, Nam Wook and Bylinskii, Zoya and Borkin, Michelle A. and Oliva, Aude and Gajos, Krzysztof Z. and Pfister, Hanspeter},
 title = {A Crowdsourced Alternative to Eye-tracking for Visualization Understanding},
 booktitle = {Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems},
 series = {CHI EA '15},
 year = {2015},
 isbn = {978-1-4503-3146-3},
 location = {Seoul, Republic of Korea},
 pages = {1349--1354},
 numpages = {6},
 publisher = {ACM},
 address = {New York, NY, USA},
  abstract={In this study we investigate the utility of using mouse clicks as an alternative for eye fixations in the context of understanding data visualizations. We developed a crowdsourced study online in which participants were presented with a series of images containing graphs and diagrams and asked to describe them. Each image was blurred so that the participant needed to click to reveal bubbles - small, circular areas of the image at normal resolution. This is similar to having a confined area of focus like the human eye fovea. We compared the bubble click data with the fixation data from a complementary eye-tracking experiment by calculating the similarity between the resulting heatmaps. A high similarity score suggests that our methodology may be a viable crowdsourced alternative to eye-tracking experiments, especially when little to no eye-tracking data is available. This methodology can also be used to complement eye-tracking studies with an additional behavioral measurement, since it is specifically designed to measure which information people consciously choose to examine for understanding visualizations.},

  pdf={nwkim15bubble-wip.pdf},
  publisherversion = {http://doi.acm.org/10.1145/2702613.2732934},
  pubtype={poster},
}

@inproceedings{weir15:learnersourcing,
 author = {Weir, Sarah and Kim, Juho and Gajos, Krzysztof Z. and Miller, Robert C.},
 title = {Learnersourcing Subgoal Labels for How-to Videos},
 booktitle = {Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work \& Social Computing},
 series = {CSCW '15},
 year = {2015},
 isbn = {978-1-4503-2922-4},
 location = {Vancouver, BC, Canada},
 pages = {405--416},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2675133.2675219},
 doi = {10.1145/2675133.2675219},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {learnersourcing, subgoal labels, video learning},
booktitle={Proceedings of CSCW'15},
abstract={Websites like YouTube host millions of how-to videos, but their interfaces are not optimized for learning. Previous research suggests that people learn more from how-to videos when the videos are accompanied by outlines showing individual steps and labels for groups of steps (subgoals). We envision an alternative video player where the steps and subgoals are displayed alongside the video. To generate this information for existing videos, we introduce learnersourcing, an approach in which intrinsically motivated learners contribute to a human computation workflow as they naturally go about learning from the videos. To demonstrate this method, we deployed a live website with a workflow for constructing subgoal labels implemented on a set of introductory web programming videos. For the four videos with the highest participation, we found that a majority of learner-generated subgoals were comparable in quality to expert-generated ones. Learners commented that the system helped them grasp the material, suggesting that our workflow did not detract from the learning experience.},

pubtype = {conference},
pdf={weir15learnersourcing.pdf},
publisherversion={http://dx.doi.org/10.1145/2675133.2675219},
}

@inproceedings{reinecke15:labinthewild,
title={LabintheWild: Conducting Large-Scale Online Experiments With Uncompensated Samples},
author = {Reinecke, Katharina and Gajos, Krzysztof Z.},
 title = {LabintheWild: Conducting Large-Scale Online Experiments With Uncompensated Samples},
 booktitle = {Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work \& Social Computing},
 series = {CSCW '15},
 year = {2015},
 isbn = {978-1-4503-2922-4},
 location = {Vancouver, BC, Canada},
 pages = {1364--1378},
 numpages = {15},
 url = {http://doi.acm.org/10.1145/2675133.2675246},
 doi = {10.1145/2675133.2675246},
 publisher = {ACM},
 address = {New York, NY, USA},
abstract={Web-based experimentation with uncompensated and unsupervised samples has the potential to support the replication, verification, extension and generation of new results with larger and more diverse sample populations than previously seen. We introduce the experimental online platform LabintheWild, which provides participants with personalized feedback in exchange for participation in behavioral studies. In comparison to conventional in-lab studies, LabintheWild enables the recruitment of participants at larger scale and from more diverse demographic and geographic backgrounds. We analyze Google Analytics data, participants' comments, and tweets to discuss how participants hear about the platform, and why they might choose to participate. Analyzing three example experiments, we additionally show that these experiments replicate previous in-lab study results with comparable data quality.},

award = {Honorable Mention},
pubtype = {conference},
pdf={reinecke15labinthewild.pdf},
publisherversion={http://dx.doi.org/10.1145/2675133.2675246},
}

@inproceedings{siangliulue15:toward,
 author = {Siangliulue, Pao and Arnold, Kenneth C. and Gajos, Krzysztof Z. and Dow, Steven P.},
 title = {Toward Collaborative Ideation at Scale: Leveraging Ideas from Others to Generate More Creative and Diverse Ideas},
 booktitle = {Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work \& Social Computing},
 series = {CSCW '15},
 year = {2015},
 isbn = {978-1-4503-2922-4},
 location = {Vancouver, BC, Canada},
 pages = {937--945},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/2675133.2675239},
 doi = {10.1145/2675133.2675239},
 publisher = {ACM},
 address = {New York, NY, USA},
abstract={A growing number of large online collaborative idea generation platforms promise that by ideating together, people can create better ideas than any would have alone. But how might these platforms best leverage the number and diversity of contributors to help each contributor generate even better ideas? Prior research suggests that seeing examples of ideas generated by others can improve one's own ideation outcomes, but the benefit may depend on how creative and how diverse (i.e., different from each other) these examples are. There already exist scalable crowd-powered mechanisms to evaluate creativity of individual ideas, but few options exist for assessing the diversity of ideas. We contribute a new scalable crowd-powered method for evaluating the diversity of sets of ideas.  The method relies on simple comparisons of similarity (is idea A more similar to B or C?) generated by a large number of non-expert contributors.  We build on prior work on multidimensional scaling and active similarity learning techniques to create an abstract spatial idea map. Our validation study reveals that human raters agree with the estimates of dissimilarity derived from our idea map as much or more than they agree with each other. The results of our main experiment demonstrate that diverse sets of examples generated automatically using our idea map improve the diversity of ideas generated by participants compared to seeing randomly selected examples. Our results also corroborate findings from prior research showing that people presented with creative examples generated more creative ideas than those who saw a set of random examples. We see this work as a step toward building more effective online systems for supporting large scale collective ideation.},

pubtype = {conference},
pdf={siangliulue15ideation.pdf},
slides-converted = {papers/2015/siangliulue15toward-slides.pdf},
publisherversion={http://dx.doi.org/10.1145/2675133.2675239},
}

@inproceedings{li15:tellab,
 author = {Li, Na and Gajos, Krzysztof Z. and Nakayama, Ken and Enos, Ryan},
 title = {TELLab: An Experiential Learning Tool for Psychology},
 booktitle = {Proceedings of the Second (2015) ACM Conference on Learning @ Scale},
 series = {L@S '15},
 year = {2015},
 isbn = {978-1-4503-3411-2},
 location = {Vancouver, BC, Canada},
 pages = {293--297},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2724660.2728678},
 doi = {10.1145/2724660.2728678},
 publisher = {ACM},
 address = {New York, NY, USA},
  abstract={In this paper, we discuss current practices and challenges of teaching psychology experiments. We review experiential learning and analogical learning pedagogies, which have informed the design of TELLab, an online platform for supporting effective experiential learning of psychology concepts.},

  pdf={li15tellab-wip.pdf},
  pubtype={poster},
  publisherversion={http://dx.doi.org/10.1145/2724660.2728678},
}

@inproceedings{kim15:exploring,
  author={Sunyoung Kim and Yasha Iravantchi and Krzysztof Z. Gajos and Barbara Grosz},
  title={Exploring Opportunities for Social Infrastructure in Congestive Heart Failure Management},
  booktitle={Proceedings of the CSCW 2015 workshop on Moving Beyond e-Health and the Quantified Self},
  year={2015},
  abstract={As population ages and chronic disease increases, new models of health care delivery are inevitable. We propose to interweave the concept of chronic care management into social infrastructure to better support elderly individuals with chronic diseases. As an exemplar, we chose and investigated Congestive Heart Failure (CHF), since it is one of serious health threats among the elderly population in western society. From a preliminary investigation of literature and prior work, we suggest two implications for social care of chronic patients: increased social awareness, and social knowledge base. This is not an exhaustive list of implications, but a starting point to open up discussions towards social care for chronic diseases.},

  pdf={skim15exploring.pdf},
  pubtype={poster},
}

@inproceedings{amir14:ai,
author={Ofra Amir and Barbara J. Grosz and Krzysztof Z. Gajos and Sonja M. Swenson and Lee M. Sanders},
title={{AI Support of Teamwork for Coordinated Care of Children with Complex Conditions}},
booktitle={{AAAI Fall Symposium: Expanding the Boundaries of Health Informatics Using AI: Making Personalized and Participatory Medicine A Reality}},
year={2014},
abstract={Children with complex health conditions require care from a large, diverse set of caregivers that includes parents and community support organizations as well as multiple types of medical professionals. Coordination of their care is essential for good outcomes, and extensive research has shown that the use of integrated, team-based care plans improves care coordination. Care plans, however, are rarely deployed in practice. This paper describes barriers to effective implementation of care plans in complex care revealed by a study of care providers treating such children. It draws on teamwork theories, identifying ways AI capabilities could enhance care plan use; describes the design of GoalKeeper, a system to support providers use of care plans; and describes initial work toward information sharing algorithms for such systems.},

pubtype = {workshop},
pdf={amir14AIsupport.pdf},
}


@inproceedings{kim14:datadriven,
author = {Kim, Juho and Guo, Philip J. and Cai, Carrie J. and Li, Shang-Wen (Daniel) and Gajos, Krzysztof Z. and Miller, Robert C.},
 title = {Data-driven Interaction Techniques for Improving Navigation of Educational Videos},
 booktitle = {Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology},
 series = {UIST '14},
 year = {2014},
 isbn = {978-1-4503-3069-5},
 location = {Honolulu, Hawaii, USA},
 pages = {563--572},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2642918.2647389},
 doi = {10.1145/2642918.2647389},
 publisher = {ACM},
 address = {New York, NY, USA},
abstract = {With an unprecedented scale of learners watching educational videos on online platforms such as MOOCs and YouTube, there is an opportunity to incorporate data generated from their interactions into the design of novel video interaction techniques. Interaction data has the potential to help not only instructors to improve their videos, but also to enrich the learning experience of educational video watchers. This paper explores the design space of data-driven interaction techniques for educational video navigation. We introduce a set of techniques that augment existing video interface widgets, including: a 2D video timeline with an embedded visualization of collective navigation traces; dynamic and non-linear timeline scrubbing; data-enhanced transcript search and keyword summary; automatic display of relevant still frames next to the video; and a visual summary representing points with high learner activity. To evaluate the feasibility of the techniques, we ran a laboratory user study with simulated learning tasks. Participants rated watching lecture videos with interaction data to be efficient and useful in completing the tasks. However, no significant differences were found in task performance, suggesting that interaction data may not always align with moment-by-moment information needs during the tasks.},

pubtype={conference},
pdf={kim-uist14-lecturescape.pdf},
video-embedded={{<iframe width="420" height="315" src="//www.youtube.com/embed/1kONuVn4Nzk?rel=0" frameborder="0" allowfullscreen></iframe>}},
publisherversion={http://dx.doi.org/10.1145/2642918.2647389},
}

@inproceedings{kim14:contentaware,
 author = {Kim, Juho and Zhang, Amy X. and Kim, Jihee and Miller, Robert C. and Gajos, Krzysztof Z.},
 title = {Content-aware Kinetic Scrolling for Supporting Web Page Navigation},
 booktitle = {Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology},
 series = {UIST '14},
 year = {2014},
 isbn = {978-1-4503-3069-5},
 location = {Honolulu, Hawaii, USA},
 pages = {123--127},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/2642918.2647401},
 doi = {10.1145/2642918.2647401},
 publisher = {ACM},
 address = {New York, NY, USA},
abstract = {Long documents are abundant on the web today, and are accessed in increasing numbers from touchscreen devices such as mobile phones and tablets. Navigating long documents with small screens can be challenging both physically and cognitively because they compel the user to scroll a great deal and to mentally filter for important content. To support navigation of long documents on touchscreen devices, we introduce content-aware kinetic scrolling, a novel scrolling technique that dynamically applies pseudo-haptic feedback in the form of friction around points of high interest within the page. This allows users to quickly find interesting content while exploring without further cluttering the limited visual space. To model degrees of interest (DOI) for a variety of existing web pages, we introduce social wear, a method for capturing DOI based on social signals that indicate collective user interest. Our preliminary evaluation shows that users pay attention to items with kinetic scrolling feedback during search, recognition, and skimming tasks.},

pubtype={conference},
pdf={kim-uist14-caks.pdf},
video-embedded={{<iframe width="560" height="315" src="//www.youtube.com/embed/MZXsrl3csQs?rel=0" frameborder="0" allowfullscreen></iframe>}},
publisherversion={http://dx.doi.org/10.1145/2642918.2647401},
}

@inproceedings{kim14:understanding,
 author = {Kim, Juho and Guo, Philip J. and Seaton, Daniel T. and Mitros, Piotr and Gajos, Krzysztof Z. and Miller, Robert C.},
 title = {Understanding In-video Dropouts and Interaction Peaks Inonline Lecture Videos},
 booktitle = {Proceedings of the First ACM Conference on Learning @ Scale Conference},
 series = {L@S '14},
 year = {2014},
 isbn = {978-1-4503-2669-8},
 location = {Atlanta, Georgia, USA},
 pages = {31--40},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2556325.2566237},
 doi = {10.1145/2556325.2566237},
 acmid = {2566237},
 publisher = {ACM},
 address = {New York, NY, USA},
abstract={With thousands of learners watching the same online lec- ture videos, analyzing video watching patterns provides a unique opportunity to understand how students learn with videos. This paper reports a large-scale analysis of in-video dropout and peaks in viewership and student activity, using second-by-second user interaction data from 862 videos in four Massive Open Online Courses (MOOCs) on edX. We find higher dropout rates in longer videos, re-watching sessions (vs first-time), and tutorials (vs lectures). Peaks in rewatching sessions and play events indicate points of interest and confusion. Results show that tutorials (vs lectures) and re-watching sessions (vs first-time) lead to more frequent and sharper peaks. In attempting to reason why peaks occur by sampling 80 videos, we observe that 61\% of the peaks accompany visual transitions in the video, e.g., a slide view to a classroom view. Based on this observation, we identify five student activity patterns that can explain peaks: starting from the beginning of a new material, returning to missed content, following a tutorial step, replaying a brief segment, and repeating a non-visual explanation. Our analysis has design implications for video authoring, editing, and interface design, providing a richer understanding of video learning on MOOCs.},

pubtype={conference},
pdf={kim14video.pdf},
publisherversion={http://dx.doi.org/10.1145/2556325.2566237},
}

@inproceedings{reinecke14:visual,
 author = {Reinecke, Katharina and Gajos, Krzysztof Z.},
 title = {Quantifying Visual Preferences Around the World},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '14},
 year = {2014},
 isbn = {978-1-4503-2473-1},
 location = {Toronto, Ontario, Canada},
 pages = {11--20},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2556288.2557052},
 doi = {10.1145/2556288.2557052},
 acmid = {2557052},
 publisher = {ACM},
 address = {New York, NY, USA},
  abstract = {Website aesthetics have been recognized as an influential moderator of people's behavior and perception. However, what users perceive as ``good design'' is subject to individual preferences, questioning the feasibility of universal design guidelines. To better understand how people's visual preferences differ, we collected 2.4 million ratings of the visual appeal of websites from nearly 40 thousand participants of diverse backgrounds. We address several gaps in the knowledge about design preferences of previously understudied groups. Among other findings, our results show that the level of colorfulness and visual complexity at which visual appeal is highest strongly varies: Females, for example, liked colorful websites more than males. A high education level generally lowers this preference for colorfulness. Russians preferred a lower visual complexity, and Macedonians liked highly colorful designs more than any other country in our dataset. We contribute a computational model and estimates of peak appeal that can be used to support rapid evaluations of website design prototypes for specific target groups.},

  pubtype={conference},
  pdf = {reinecke14visual.pdf},
  publisherversion={http://dx.doi.org/10.1145/2556288.2557052},
}

@inproceedings{kim14:crowdsourcing,
 author = {Kim, Juho and Nguyen, Phu Tran and Weir, Sarah and Guo, Philip J. and Miller, Robert C. and Gajos, Krzysztof Z.},
 title = {Crowdsourcing Step-by-step Information Extraction to Enhance Existing How-to Videos},
 booktitle = {Proceedings of the 32Nd Annual ACM Conference on Human Factors in Computing Systems},
 series = {CHI '14},
 year = {2014},
 isbn = {978-1-4503-2473-1},
 location = {Toronto, Ontario, Canada},
 pages = {4017--4026},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2556288.2556986},
 doi = {10.1145/2556288.2556986},
 acmid = {2556986},
 publisher = {ACM},
 address = {New York, NY, USA},
  abstract = {<p>Millions of learners today use how-to videos to master new skills in a variety of domains. But browsing such videos is often tedious and inefficient because video player interfaces are not optimized for the unique step-by-step structure of such videos. This research aims to improve the learning experience of existing how-to videos with step-by-step annotations.</p><p>We first performed a formative study to verify that annotations are actually useful to learners. We created ToolScape, an interactive video player that displays step descriptions and intermediate result thumbnails in the video timeline. Learners in our study performed better and gained more self-efficacy using ToolScape versus a traditional video player.</p><p>To add the needed step annotations to existing how-to videos at scale, we introduce a novel crowdsourcing workflow. It extracts step-by-step structure from an existing video, including step times, descriptions, and before and after images. We introduce the Find-Verify-Expand design pattern for temporal and visual annotation, which applies clustering, text processing, and visual analysis algorithms to merge crowd output. The workflow does not rely on domain-specific customization, works on top of existing videos, and recruits untrained crowd workers. We evaluated the workflow with Mechanical Turk, using 75 cooking, makeup, and Photoshop videos on YouTube. Results show that our workflow can extract steps with a quality comparable to that of trained annotators across all three domains with 77\% precision and 81\% recall.</p>},

  award = {Honorable Mention},
  pubtype={conference},
  pdf = {kim14crowdsourcing.pdf},
  image = {papers/2014/kim14crowdsourcing.jpg},
  video-embedded={{<iframe width="420" height="315" src="//www.youtube.com/embed/-l5AKSa0ymo?rel=0" frameborder="0" allowfullscreen></iframe>}},
  publisherversion={http://dx.doi.org/10.1145/2556288.2556986},
}

@inproceedings{li14:adaptive,
 author = {Li, Louis and Gajos, Krzysztof Z.},
 title = {Adaptive Click-and-cross: Adapting to Both Abilities and Task Improves Performance of Users with Impaired Dexterity},
 booktitle = {Proceedings of the 19th International Conference on Intelligent User Interfaces},
 series = {IUI '14},
 year = {2014},
 isbn = {978-1-4503-2184-6},
 location = {Haifa, Israel},
 pages = {299--304},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2557500.2557511},
 doi = {10.1145/2557500.2557511},
 acmid = {2557511},
 publisher = {ACM},
 address = {New York, NY, USA},
abstract = {Computer users with impaired dexterity often have difficulty accessing small, densely packed user interface elements. Past research in software-based solutions has mainly employed two approaches: modifying the interface and modifying the interaction with the cursor. Each approach, however, has limitations. Modifying the user interface by enlarging interactive elements makes access efficient for simple interfaces but increases the cost of navigation for complex ones by displacing items to screens that require tabs or scrolling to reach. Modifying the interaction with the cursor makes access possible to unmodified interfaces but may perform poorly on densely packed targets or require the user to perform multiple steps. We developed a new approach that combines the strengths of the existing approaches while minimizing their shortcomings, introducing only minimal distortion to the original interface while making access to frequently used parts of the user interface efficient and access to all other parts possible. We instantiated this concept as Adaptive Click-and-Cross, a novel interaction technique. Our user study demonstrates that, for sufficiently complex interfaces, Adaptive Click-andCross slightly improves the performance of users with impaired dexterity compared to only modifying the interface or only modifying the cursor.},

project={ability,aui},
pubtype={conference},
pdf = {li14acnx.pdf},
image = {http://iis.seas.harvard.edu/projects/images/acnx.png},
}

@inproceedings{huang14:active,
 author = {Huang, Cheng-Zhi Anna and Duvenaud, David and Arnold, Kenneth C. and Partridge, Brenton and Oberholtzer, Josiah W. and Gajos, Krzysztof Z.},
 title = {Active Learning of Intuitive Control Knobs for Synthesizers Using Gaussian Processes},
 booktitle = {Proceedings of the 19th International Conference on Intelligent User Interfaces},
 series = {IUI '14},
 year = {2014},
 isbn = {978-1-4503-2184-6},
 location = {Haifa, Israel},
 pages = {115--124},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2557500.2557544},
 doi = {10.1145/2557500.2557544},
 acmid = {2557544},
 publisher = {ACM},
 address = {New York, NY, USA},
abstract = {<p>Typical synthesizers only provide controls to the low-level parameters of sound synthesis, such as wave-shapes or filter envelopes. In contrast, composers often want to adjust and express higher-level qualities, such as how ``scary'' or ``steady'' sounds are perceived to be.</p><p>We develop a system which allows users to directly control abstract, high-level qualities of sounds. To do this, our system learns functions that map from synthesizer control settings to perceived levels of high-level qualities. Given these functions, our system can generate high-level knobs that directly adjust sounds to have more or less of those qualities. We model the functions mapping from control-parameters to the degree of each high-level quality using Gaussian processes, a nonparametric Bayesian model. These models can adjust to the complexity of the function being learned, account for nonlinear interaction between control-parameters, and allow us to characterize the uncertainty about the functions being learned.</p><p>By tracking uncertainty about the functions being learned, we can use active learning to quickly calibrate the tool, by querying the user about the sounds the system expects to most improve its performance. We show through simulations that this model-based active learning approach learns high-level knobs on certain classes of target concepts faster than several baselines, and give examples of the resulting automatically-constructed knobs which adjust levels of non-linear, high-level concepts.</p>
},
  
pubtype={conference},
pdf = {huang14knobs.pdf},
}

@inproceedings{kim14:leveraging,
title={Leveraging Video Interaction Data and Content Analysis to Improve Video Learning},
author={Juho Kim and Shang-Wen (Daniel) Li and Carrie J. Cai and Krzysztof Z. Gajos and Robert C. Miller},
booktitle={Proceedings of the CHI 2014 Learning Innovation at Scale workshop},
year={2014},
abstract={Video has emerged as a dominant medium for online education, as witnessed by millions of students learning from educational videos on Massive Open Online Courses (MOOCs), Khan Academy, and YouTube. The large-scale data collected from students' interactions with video provide a unique opportunity to analyze and improve the video learning experience. We combine click-level interaction data, such as pausing, resuming, or navigating between points in the video, and video content analysis, such as visual, text, and speech, to analyze peaks in viewership and student activity. Such analysis can reveal points of interest or confusion in the video, and suggest production and editing improvements. Furthermore, we envision novel video interfaces and learning platforms that automatically adapt to learners' collective watching behaviors.},

pubtype={workshop},
pdf={kim14leveraging.pdf},
}

@inproceedings{komarov14:organic,
title={Organic Peer Assessment},
author={Steven Komarov and Krzysztof Z. Gajos},
booktitle={Proceedings of the CHI 2014 Learning Innovation at Scale workshop},
year={2014},
abstract={We present a web-based tool for a type of peer assessment we dubbed organic. In organic peer assessment there are no upper or lower limits on the number of assignments each peer has to review, avoiding the common issue of prematurely coercing students into activities they might fear and dislike. Instead, peer assessment occurs as a side effect of activities students find intrinsically motivating. We outline the basic set of functionality required for the implementation of our vision for peer assessment in an online environment and present the results of a preliminary study we conducted in a flipped classroom. We found that the quality of the summative assessment produced by the peers matched that of experts, and we encountered strong evidence that our peer assessment implementation had positive effects on achievement. We conclude with a discussion arguing that organic peer assessment is a valuable technique-distinct from formal peer assessment-for deployment in MOOCs.},

pubtype={workshop},
pdf={komarov14organic.pdf},
}

@article{borkin13:evaluation,
  title={Evaluation of filesystem provenance visualization tools},
  author={Borkin, Michelle A and Yeh, Chelsea S and Boyd, Madelaine and Macko, Peter and Gajos, KZ and Seltzer, M and Pfister, H},
  journal={IEEE transactions on visualization and computer graphics},
  volume={19},
  number={12},
  pages={2476--2485},
  year={2013},
  abstract = {Having effective visualizations of filesystem provenance data is valuable for understanding its complex hierarchical structure. The most common visual representation of provenance data is the node-link diagram. While effective for understanding local activity, the node-link diagram fails to offer a high-level summary of activity and inter-relationships within the data. We present a new tool, InProv, which displays filesystem provenance with an interactive radial-based tree layout. The tool also utilizes a new time-based hierarchical node grouping method for filesystem provenance data we developed to match the user's mental model and make data exploration more intuitive. We compared InProv to a conventional node-link based tool, Orbiter, in a quantitative evaluation with real users of filesystem provenance data including provenance data experts, IT professionals, and computational scientists. We also compared in the evaluation our new node grouping method to a conventional method. The results demonstrate that InProv results in higher accuracy in identifying system activity than Orbiter with large complex data sets. The results also show that our new timebased hierarchical node grouping method improves performance in both tools, and participants found both tools significantly easier to use with the new time-based node grouping method. Subjective measures show that participants found InProv to require less mental activity, less physical activity, less work, and is less stressful to use. Our study also reveals one of the first cases of gender differences in visualization; both genders had comparable performance with InProv, but women had a significantly lower average accuracy (56%) compared to men (70%) with Orbiter.},

  pdf = {borkin13inprov.pdf},
  pubtype={journal},
  publisherversion = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6634189},
}

@inproceedings{li13:adaptive,
 author = {Li, Louis},
 title = {Adaptive Click-and-cross: An Interaction Technique for Users with Impaired Dexterity},
 booktitle = {Proceedings of the 15th International ACM SIGACCESS Conference on Computers and Accessibility},
 series = {ASSETS '13},
 year = {2013},
 isbn = {978-1-4503-2405-2},
 location = {Bellevue, Washington},
 pages = {79:1--79:2},
 articleno = {79},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2513383.2517036},
 doi = {10.1145/2513383.2517036},
 acmid = {2517036},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {accessibility, adaptive user interface, area cursors},
abstract = {Computer users with impaired dexterity face difficulties with tradi­ tional pointing methods, particularly on small, densely packed user interfaces. Past research in software-based solutions can usually be categorized as one of two approaches. They either modify the user interface to fit the users' needs or modify the user's interaction with the cursor. Each approach, however, has limitations. Modify­ ing the user interface increases the navigation cost of some items by displacing them to other screens, while enhanced area cursors, a pointing technique for small, densely packed targets, require users to perform multiple steps to acquire a target. This study aims to minimize the costs of these two approaches through a new inter­ action technique, Adaptive Click-and-Cross. The technique was found to lower error rates relative to traditional pointing (8.5% vs 16.0%) with slightly faster acquisition times compared to two other techniques for modifying the user interface or cursor.},

pubtype = {poster},
pdf = {li13adaptive.pdf},
publisherversion = {http://dl.acm.org/citation.cfm?doid=2513383.2517036},
}

@inproceedings{law13:curio,
title = {Curio: A Platform for Supporting Mixed-Expertise Crowdsourcing},
author = {Edith Law and Conner Dalton and Nick Merrill and Albert Young and Krzysztof Z. Gajos},
booktitle = {Proceedings of HCOMP 2013},
year = {2013},
publisher = {AAAI Press},
abstract = {Curio is a platform that enables researchers in the sciences and humanities, who are domain experts but not necessarily technically savvy, to create, monitor and control complex crowdsourcing projects with minimal effort. With Curio, we aim to contribute to the practice of citizen science and to make fundamental contributions to the study of human computation by developing new interfaces and algorithms for supporting mixed-expertise crowdsourcing, task decomposition, incentive design and quality control.},
note = {To appear.},
numpages = {2},

pdf = {law13curio.pdf},
pubtype = {demo},
}

@inproceedings{komarov13:crowdsourcing,
 author = {Komarov, Steven and Reinecke, Katharina and Gajos, Krzysztof Z.},
 title = {Crowdsourcing performance evaluations of user interfaces},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '13},
 year = {2013},
 isbn = {978-1-4503-1899-0},
 location = {Paris, France},
 pages = {207--216},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2470654.2470684},
 doi = {10.1145/2470654.2470684},
 acmid = {2470684},
 publisher = {ACM},
 address = {New York, NY, USA},

abstract = {Online labor markets, such as Amazon's Mechanical Turk (MTurk), provide an attractive platform for conducting human subjects experiments because the relative ease of recruitment, low cost, and a diverse pool of potential participants enable larger-scale experimentation and faster experimental revision cycle compared to lab-based settings. However, because the experimenter gives up the direct control over the participants' environments and behavior, concerns about the quality of the data collected in online settings are pervasive. In this paper, we investigate the feasibility of conducting online performance evaluations of user interfaces with anonymous, unsupervised, paid participants recruited via MTurk. We implemented three performance experiments to re-evaluate three previously well-studied user interface designs. We conducted each experiment both in lab and online with participants recruited via MTurk. The analysis of our results did not yield any evidence of significant or substantial differences in the data collected in the two settings: All statistically significant differences detected in lab were also present on MTurk and the effect sizes were similar. In addition, there were no significant differences between the two settings in the raw task completion times, error rates, consistency, or the rates of utilization of the novel interaction mechanisms introduced in the experiments. These results suggest that MTurk may be a productive setting for conducting performance evaluations of user interfaces providing a complementary approach to existing methodologies.},

pubtype={conference},
pdf={komarov13crowdsourcing.pdf},
resources = {Data},
resources-url = {http://iis.seas.harvard.edu/resources/},
publisherversion = {http://dl.acm.org/citation.cfm?doid=2470654.2470684},
image={http://iis.seas.harvard.edu/projects/images/LABvsMT.png},
}

@inproceedings{reinecke13:predicting,
 author = {Reinecke, Katharina and Yeh, Tom and Miratrix, Luke and Mardiko, Rahmatri and Zhao, Yuechen and Liu, Jenny and Gajos, Krzysztof Z.},
 title = {Predicting users' first impressions of website aesthetics with a quantification of perceived visual complexity and colorfulness},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '13},
 year = {2013},
 isbn = {978-1-4503-1899-0},
 location = {Paris, France},
 pages = {2049--2058},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2470654.2481281},
 doi = {10.1145/2470654.2481281},
 acmid = {2481281},
 publisher = {ACM},
 address = {New York, NY, USA},
abstract = {Users make lasting judgments about a website's appeal within a split second of seeing it for the first time. This first impression is influential enough to later affect their opinions of a site's usability and trustworthiness. In this paper, we demonstrate a means to predict the initial impression of aesthetics based on perceptual models of a website's colorfulness and visual complexity. In an online study, we collected ratings of colorfulness, visual complexity, and visual appeal of a set of 450 websites from 548 volunteers. Based on these data, we developed computational models that accurately measure the perceived visual complexity and colorfulness of website screenshots. In combination with demographic variables such as a user's education level and age, these models explain approximately half of the variance in the ratings of aesthetic appeal given after viewing a website for 500ms only.},

pubtype={conference},
pdf={reinecke13aesthetics.pdf},
award = {Honorable Mention},
resources = {Data},
resources-url = {http://iis.seas.harvard.edu/resources/aesthetics-chi13/},
publisherversion = {http://dl.acm.org/citation.cfm?doid=2470654.2481281},
}

@inproceedings{flatla13:sprweb,
 author = {Flatla, David R. and Reinecke, Katharina and Gutwin, Carl and Gajos, Krzysztof Z.},
 title = {SPRWeb: preserving subjective responses to website colour schemes through automatic recolouring},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '13},
 year = {2013},
 isbn = {978-1-4503-1899-0},
 location = {Paris, France},
 pages = {2069--2078},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2470654.2481283},
 doi = {10.1145/2470654.2481283},
 acmid = {2481283},
 publisher = {ACM},
 address = {New York, NY, USA},
abstract={Colours are an important part of user experiences on the Web. Colour schemes influence the aesthetics, first impressions and long-term engagement with websites. However, five percent of people perceive a subset of all colours because they have colour vision deficiency (CVD), resulting in an unequal and less-rich user experience on the Web. Traditionally, people with CVD have been supported by recolouring tools that improve colour differentiability, but do not consider the subjective properties of colour schemes while recolouring. To address this, we developed SPRWeb, a tool that recolours websites to preserve subjective responses and improve colour differentiability thus enabling users with CVD to have similar online experiences. To develop SPRWeb, we extended existing models of non-CVD subjective responses to CVD, then used this extended model to steer the recolouring process. In a lab study, we found that SPRWeb did significantly better than a standard recolouring tool at preserving the temperature and naturalness of websites, while achieving similar weight and differentiability preservation. We also found that recolouring did not preserve activity, and hypothesize that visual complexity influences activity more than colour. SPRWeb is the first tool to automatically preserve the subjective and perceptual properties of website colour schemes thereby equalizing the colour-based web experience for people with CVD.},

pubtype={conference},
pdf={flatla13sprweb.pdf},
video-embedded={<iframe width="640" height="360" src="https://www.youtube.com/embed/vGKKUH-Yhnc" frameborder="0" allowfullscreen></iframe>},
project={ability},
award = {Best Paper Award},
publisherversion = {http://dl.acm.org/citation.cfm?doid=2468356.2479521},
}

@inproceedings{reinecke13:many,
 author = {Reinecke, Katharina and Flatla, David R. and Solovey, Erin and Gutwin, Carl and Gajos, Krzysztof Z. and Heer, Jeffrey},
 title = {Many people, many eyes: aggregating influences of visual perception on user interface design},
 booktitle = {CHI '13 Extended Abstracts on Human Factors in Computing Systems},
 series = {CHI EA '13},
 year = {2013},
 isbn = {978-1-4503-1952-2},
 location = {Paris, France},
 pages = {3299--3302},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/2468356.2479671},
 doi = {10.1145/2468356.2479671},
 acmid = {2479671},
 publisher = {ACM},
 address = {New York, NY, USA},
abstract = {Many factors influence a user's visual perception of an interface (e.g., culture, gender, visual impairment). In general, interface researchers and designers have considered these factors in isolation, without considering the combined effect of every factor influencing the visual perception of the user. As a result, interfaces have been optimized for single factors (e.g., improving accessibility for individuals with low vision), at the expense of optimizing for the individual's visual perception experience (e.g., considering cultural preferences and lighting conditions while assisting users with low vision). In this workshop, we will begin the process of combining the broad range of visual perception knowledge to create a holistic approach to understanding users' visual perception. The resulting knowledge pool will be used for generating interfaces better suited to the full range of users' visual perception abilities.},

pubtype={other},
pdf={reinecke13manyPeople.pdf},
}

@inproceedings{kim13:learnersourcing,
 author = {Kim, Juho and Miller, Robert C. and Gajos, Krzysztof Z.},
 title = {Learnersourcing subgoal labeling to support learning from how-to videos},
 booktitle = {CHI '13 Extended Abstracts on Human Factors in Computing Systems},
 series = {CHI EA '13},
 year = {2013},
 isbn = {978-1-4503-1952-2},
 location = {Paris, France},
 pages = {685--690},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2468356.2468477},
 doi = {10.1145/2468356.2468477},
 acmid = {2468477},
 publisher = {ACM},
 address = {New York, NY, USA},

abstract={Subgoal labeling is a technique known to support learning new knowledge by clustering a group of steps into a higher-level conceptual unit. It has been shown to improve learning by helping learners to form the right mental model. While many learners view video tutorials nowadays, subgoal labels are often not available unless manually provided at production
time. This work addresses the challenge of collecting and presenting subgoal labels to a large number of video tutorials. We introduce a mixed-initiative approach to collect subgoal labels in a scalable and efficient manner. The key component of this method is learnersourcing, which channels learners' activities using the video interface into useful input to the system. The presented method will contribute to the broader availability of subgoal labels in how-to videos.},

pubtype = {poster},
pdf = {kim13learnersourcing.pdf},
}

@inproceedings{reinecke13:doodle,
 author = {Reinecke, Katharina and Nguyen, Minh Khoa and Bernstein, Abraham and N\"{a}f, Michael and Gajos, Krzysztof Z.},
 title = {Doodle around the world: online scheduling behavior reflects cultural differences in time perception and group decision-making},
 booktitle = {Proceedings of the 2013 conference on Computer supported cooperative work},
 series = {CSCW '13},
 year = {2013},
 isbn = {978-1-4503-1331-5},
 location = {San Antonio, Texas, USA},
 pages = {45--54},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2441776.2441784},
 doi = {10.1145/2441776.2441784},
 acmid = {2441784},
 publisher = {ACM},
 address = {New York, NY, USA},
abstract={Event scheduling is a group decision-making process in which social dynamics influence people's choices and the overall outcome. As a result, scheduling is not simply a matter of finding a mutually agreeable time, but a process that is shaped by social norms and values, which can highly vary between countries. To investigate the influence of national culture on people's scheduling behavior we analyzed more than 1.5 million Doodle date/time polls from 211 countries. We found strong correlations between characteristics of national culture and several behavioral phenomena, such as that poll participants from collectivist countries respond earlier, agree to fewer options but find more consensus than predominantly individualist societies. Our study provides empirical evidence of behavioral differences in group decision-making and time perception with implications for cross-cultural collaborative work.},

pubtype={conference},
pdf={reinecke13doodle.pdf},
resources = {Data},
resources-url = {http://iis.seas.harvard.edu/resources/doodle/},
}

@inproceedings{mao12:turkserver,
title={TurkServer: Enabling Synchronous and Longitudinal Online Experiments},
  author={Mao, A. and Chen, Y. and Gajos, K.Z. and Parkes, D.C. and Procaccia, A.D. and Zhang, H.},
  booktitle={Proceedings of HCOMP'12},
  year={2012},
abstract = {With the proliferation of online labor markets and other social computing platforms, online experiments have become a low-cost and scalable way to empirically test hypotheses and mechanisms in both human computation and social science. Yet, despite the potential in designing more powerful and expressive on-line experiments using multiple subjects, researchers still face many technical and logistical difficulties. We see synchronous and longitudinal experiments involving real-time interaction between participants as a dual-use paradigm for both human computation and social science, and present TurkServer, a platform that facilitates these types of experiments on Amazon Mechanical Turk. Our work has the potential to make more fruitful online experiments accessible to researchers in many different fields.},

pubtype = {workshop},
pdf = {mao12-turkserver.pdf},
publisherversion = {http://www.aaai.org/ocs/index.php/WS/AAAIW12/paper/view/5315},
}

@article{gajos12:personalized,
 author = {Gajos, Krzysztof Z. and Hurst, Amy and Findlater, Leah},
 title = {Personalized dynamic accessibility},
 journal = {interactions},
 issue_date = {March + April 2012},
 volume = {19},
 number = {2},
 month = {March},
 year = {2012},
 issn = {1072-5520},
 pages = {69--73},
 numpages = {5},
 doi = {10.1145/2090150.2090167},
 acmid = {2090167},
 publisher = {ACM},
 address = {New York, NY, USA},
abstract = {It is a cliche to point out that computers and the Internet have entered all parts of our lives. We need them at work; governments urge us to file our taxes online; students are required to use them in their classes; online businesses offer better deals than their brick-and-mortar counterparts; and it is becoming more difficult to maintain relationships without access to social networking and social media sites. Public discourse about accessibility focuses on the assertion that access to these technologies is essential for meaningful participation in today's society. Unfortunately, compliance with accessibility guidelines and standards is still not a part of mainstream software engineering and user interface design practice. As
a result, we must remind, beg, and threaten developers to make software accessible. But is this sufficient? Are we blinding ourselves to tomorrow's challenges as we fight yesterday's battles?<br/><br/>
We argue that it is both the possibility and the efficiency of access that are necessary for meaningful and equitable participation in society. As larger fractions of our personal and professional activities are conducted using computers, inefficient access limits what an individual can achieve. We propose a longterm vision of Personalized Dynamic Accessibility: We believe that user interfaces will enable more effective interaction if they reflect each person's unique abilities, devices, and environment.},

project = {ability},
pubtype = {other},
publisherversion = {http://doi.acm.org/10.1145/2090150.2090167},
authorizer = {http://dl.acm.org/authorize?6618349},
pdf = {http://www.eecs.harvard.edu/~kgajos/papers/authorizer.html?url=http://dl.acm.org/authorize?6618349},
}

@incollection{jameson12:systems,
	Author = {Anthony Jameson and Krzysztof Z. Gajos},
	Booktitle = {Human-Computer Interaction Handbook: Fundamentals, Evolving Technologies, and Emerging Applications},
	Edition = {Third Edition},
	Editor = {Julie A. Jacko},
	Publisher = {CRC Press},
	Title = {Systems That Adapt to Their Users},
	Year = {2012},

pubtype = {bookchapter},
}

@inproceedings{zhang12:human,
author = {Zhang, Haoqi and Law, Edith and Miller, Rob and Gajos, Krzysztof and Parkes, David and Horvitz, Eric},
 title = {Human computation tasks with global constraints},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 series = {CHI '12},
 year = {2012},
 isbn = {978-1-4503-1015-4},
 location = {Austin, Texas, USA},
 pages = {217--226},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2207676.2207708},
 doi = {10.1145/2207676.2207708},
 acmid = {2207708},
 publisher = {ACM},
 address = {New York, NY, USA},


abstract = {An important class of tasks that are underexplored in current human computation systems are complex tasks with global constraints. One example of such a task is itinerary planning, where solutions consist of a sequence of activities that meet requirements specified by the requester. In this paper, we focus on the crowdsourcing of such plans as a case study of constraint-based human computation tasks and introduce a collaborative planning system called Mobi that illustrates a novel crowdware paradigm. Mobi presents a single interface that enables crowd participants to view the current solution context and make appropriate contributions based on current needs. We conduct experiments that explain how Mobi enables a crowd to effectively and collaboratively resolve global constraints, and discuss how the design principles behind Mobi can more generally facilitate a crowd to tackle problems involving global constraints.},
pdf = {zhang12-mobi.pdf},
pubtype = {conference},
award = {Honorable Mention},
}

@inproceedings{gajos12:accurate,
author = {Gajos, Krzysztof and Reinecke, Katharina and Herrmann, Charles},
 title = {Accurate measurements of pointing performance from in situ observations},
 booktitle = {Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems},
 series = {CHI '12},
 year = {2012},
 isbn = {978-1-4503-1015-4},
 location = {Austin, Texas, USA},
 pages = {3157--3166},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2208636.2208733},
 doi = {10.1145/2208636.2208733},
 publisher = {ACM},
 address = {New York, NY, USA},

abstract = {We present a method for obtaining lab-quality measurements of pointing performance from unobtrusive observations of natural in situ interactions. Specifically, we have developed a set of user-independent classifiers for discriminating between deliberate, targeted mouse pointer movements and those movements that were affected by any extraneous factors. To develop and validate these classifiers, we developed logging software to unobtrusively record pointer trajectories as participants naturally interacted with their computers over the course of several weeks.  Each participant also performed a set of pointing tasks in a formal study set-up. For each movement, we computed a set of measures capturing nuances of the trajectory and the speed, acceleration, and jerk profiles. Treating the observations from the formal study as positive examples of deliberate, targeted movements and the in situ observations as unlabeled data with an unknown mix of deliberate and distracted interactions, we used a recent advance in machine learning to develop the classifiers. Our results show that, on four distinct metrics, the data collected in-situ and filtered with our classifiers closely matches the results obtained from the formal experiment.},
pdf = {gajos12-accurateMeasurements.pdf},
pubtype = {conference},
project = {ability},
resources = {Data and Source Code},
resources-url = {http://iis.seas.harvard.edu/resources/MovementClassifier/},
authorizer = {http://dl.acm.org/authorize?6762999},
}


@inproceedings{kim12:photoshop,
 author = {Kim, Juho and Malley, Benjamin and Brandt, Joel and Dontcheva, Mira and Joseph, Diana and Gajos, Krzysztof Z. and Miller, Robert C.},
 title = {Photoshop with friends: a synchronous learning community for graphic design},
 booktitle = {Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work Companion},
 series = {CSCW '12},
 year = {2012},
 isbn = {978-1-4503-1051-2},
 location = {Seattle, Washington, USA},
 pages = {271--272},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2141512.2141598},
 doi = {10.1145/2141512.2141598},
 acmid = {2141598},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {graphic design, online learning, synchronous help},

abstract = {Photoshop with Friends is an online community of learners exchanging just-in-time help on graphic design tasks. The system attempts to provide an interactive, visual, context-aware, and personalized mode of learning. Developed as a Facebook application, Photoshop with Friends allows users to help each other in live sessions, with built-in screen sharing, recording, and voice chat support. Major design decisions are guided by two laboratory studies that identified challenges in learning graphic design skills on the web.},
pdf = {kim12-photoshop.pdf},
publisherversion = {http://dx.doi.org/10.1145/2141512.2141598},
pubtype = {demo},
}

@inproceedings{hurst11:dynamic,
 author = {Hurst, Amy and Gajos, Krzysztof and Findlater, Leah and Wobbrock, Jacob and Sears, Andrew and Trewin, Shari},
 title = {Dynamic accessibility: accommodating differences in ability and situation},
 booktitle = {Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems},
 series = {CHI EA '11},
 year = {2011},
 isbn = {978-1-4503-0268-5},
 location = {Vancouver, BC, Canada},
 pages = {41--44},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/1979742.1979589},
 doi = {http://doi.acm.org/10.1145/1979742.1979589},
 acmid = {1979589},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {assistive technology, intelligent user interfaces, interaction design, mobile devices, situational impairment, user modeling},
abstract = {Human abilities are idiosyncratic and may change frequently. Static one-size-fits-many accessibility solutions miss the opportunities that arise from careful consideration of an individual's abilities and fail to address the sometimes dynamic aspect of those abilities, such as when a user's activity or context causes a situational impairment. The goal of this workshop is to bring together researchers and practitioners in accessibility, mobile HCI, and interactive intelligent systems who are pursuing agile, data-driven approaches that enable interactive systems to adapt or become adapted to the needs and abilities of a particular individual in a particular context.},

pdf = {hurst-dynamic-chi11.pdf},
publisherversion = {http://doi.acm.org/10.1145/1979742.1979589},
authorizer = {http://dl.acm.org/authorize?408881},
project = {ability},
pubtype = {other},
}


@inproceedings{noronha11:platemate,
author = {Jon Noronha and Eric Hysen and Haoqi Zhang and Krzysztof Z. Gajos},
title = {PlateMate: Crowdsourcing Nutrition Analysis from Food Photographs},
booktitle = {Proceedings of the 24th annual ACM symposium on User interface software and technology},
 series = {UIST '11},
 year = {2011},
 isbn = {978-1-4503-0716-1},
 location = {Santa Barbara, California, USA},
 pages = {1--12},
 numpages = {12},
 publisher = {ACM},
 address = {New York, NY, USA},

abstract = {PlateMate allows users to take photos of their meals and receive estimates of food intake and composition. Accurate awareness of this information is considered a prerequisite to successful change of eating habits, but current methods for food logging via self-reporting, expert observation, or algorithmic analysis are time-consuming, expensive, or inaccurate.  PlateMate crowdsources nutritional analysis from photographs using Amazon Mechanical Turk, automatically coordinating untrained workers to estimate a meal's calories, fat, carbohydrates, and protein.  We present the Management framework for crowdsourcing complex tasks, which supports PlateMate's decomposition of the nutrition analysis workflow. Two evaluations show that the PlateMate system is nearly as accurate as a trained dietitian and easier to use for most users than traditional self-reporting, while remaining robust for general use across a wide variety of meal types.},

pdf = {noronha-platemate-uist11.pdf},
pubtype = {conference},
publisherversion = {http://dx.doi.org/10.1145/2047196.2047198},
authorizer = {http://dl.acm.org/authorize?6592100},
image = {projects/images/platemate.png},
resources = {Data},
resources-url = {http://iis.seas.harvard.edu/resources/PlateMate/},
}


@article{borkin11:evaluation,
title = {Evaluation of Artery Visualizations for Heart Disease Diagnosis},
author = {Michelle A. Borkin and Krzysztof Z. Gajos and Amanda Peters and Dimitrios Mitsouras and Simone Melchionna and Frank J. Rybicki and Charles L. Feldman and Hanspeter Pfister},
year = {2011},
journal = {IEEE Transactions on Visualization and Computer Graphics (Proceedings of Information Visualization 2011)},
volume = {17},
number = {12},
month = {December},
abstract = {Heart disease is the number one killer in the United States, and finding indicators of the disease at an early stage is critical for treatment and prevention. In this paper we evaluate visualization techniques that enable the diagnosis of coronary artery disease. A key physical quantity of medical interest is endothelial shear stress (ESS). Low ESS has been associated with sites of lesion formation and rapid progression of disease in the coronary arteries. Having effective visualizations of a patient's ESS data is vital for the quick and thorough non-invasive evaluation by a cardiologist. We present a task taxonomy for hemodynamics based on a formative user study with domain experts. Based on the results of this study we developed HemoVis, an interactive visualization application for heart disease diagnosis that uses a novel 2D tree diagram representation of coronary artery trees. We present the results of a formal quantitative user study with domain experts that evaluates the effect of 2D versus 3D artery representations and of color maps on identifying regions of low ESS. We show statistically significant results demonstrating that our 2D visualizations are more accurate and efficient than 3D representations, and that a perceptually appropriate color map leads to fewer diagnostic mistakes than a rainbow color map.},


pubtype = {journal},
pdf = {borkin11-infoviz.pdf},
publisherversion = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6065015&tag=1},
image = {papers/images/hemoviz-thumb.png},
}

@inproceedings{reinecke11:culturalabilities,
author = {Katharina Reinecke and Krzysztof Z. Gajos},
title = {One size fits many Westerners: How Cultural Abilities Challenge UI Design},
booktitle = {Proceedings of the Workshop on Dynamic Accessibility: Detecting and Accommodating Differences in Ability and Situation at CHI'11},
year = 2011,
abstract = {Cultural influences on our behavior are partly reflected in neuro-anatomical changes in our brains, altering our abilities to perceive and interpret information. This paper points out possible consequences of such ``cultural abilities'' for user interface design, and outlines challenges for systems that adapt to their users. Specifically, we describe how culture could influence our design decisions of when, how, what, why, and where to adapt.},

pubtype = {workshop},
pdf = {Reinecke_Gajos_CulturalAbilities.pdf}
}



@article{wobbrock11:abd,
 author = {Wobbrock, Jacob O. and Kane, Shaun K. and Gajos, Krzysztof Z. and Harada, Susumu and Froehlich, Jon},
 title = {Ability-Based Design: Concept, Principles and Examples},
 journal = {ACM Trans. Access. Comput.},
 issue_date = {April 2011},
 volume = {3},
 issue = {3},
 month = {April},
 year = {2011},
 issn = {1936-7228},
 pages = {9:1--9:27},
 articleno = {9},
 numpages = {27},
 url = {http://doi.acm.org/10.1145/1952383.1952384},
 doi = {http://doi.acm.org/10.1145/1952383.1952384},
 acmid = {1952384},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Ability-based design, adaptive user interfaces, assistive technology, computer access, design for all, inclusive design, universal design, universal usability, user interfaces for all},

abstract = {Current approaches to accessible computing share a common goal of making technology accessible to users with disabilities. Perhaps because of this goal, they may also share a tendency to centralize disability rather than ability. We present a refinement to these approaches called ability-based design that consists of focusing on ability throughout the design process in an effort to create systems that leverage the full range of human potential. Just as user-centered design shifted the focus of interactive system design from systems to users, ability-based design attempts to shift the focus of accessible design from disability to ability. Although prior approaches to accessible computing may consider users' abilities to some extent, ability-based design makes ability its central focus. We offer seven ability-based design principles and describe the projects that inspired their formulation. We also present a research agenda for ability-based design.},
project = {ability},
pubtype = {journal},
pdf = {wobbrock11abd.pdf},
publisherversion = {http://doi.acm.org/10.1145/1952383.1952384},
authorizer = {http://dl.acm.org/authorize?078663},
}


@inproceedings{jayatilaka11:evaluating,
	address = {New York, NY, USA},
	author = {Lahiru G. Jayatilaka and Luca F. Bertuccelli and James Staszewski and Krzysztof Z. Gajos},
	booktitle = {CHI '11: Proceeding of the annual SIGCHI conference on Human factors in computing systems},
	publisher = {ACM},
	title = {Evaluating a Pattern-Based Visual Support Approach for Humanitarian Landmine Clearance},
	year = {2011},
abstract = {Unexploded landmines have severe post-conflict humanitarian repercussions: landmines cost lives, limbs and land. For deminers engaged in humanitarian landmine clearance, metal detectors remain the primary detection tool as more sophisticated technologies fail to get adopted due to restrictive cost, low reliability, and limited robustness.  Metal detectors are, however, of limited effectiveness, as modern landmines contain only minimal amounts of metal, making them difficult to distinguish from the ubiquitous but harmless metallic clutter littering post-combat areas.  We seek to improve the safety and efficiency of the demining process without introducing an inviable replacement for the metal detectors.  Instead, we propose and evaluate a novel, pattern-based visual support approach inspired by the documented strategies employed by expert deminers. In our laboratory study, participants provided with a prototype of our support tool were 80% less likely to mistake a mine for harmless clutter.  A follow-up study demonstrates the potential of our pattern-based approach to enable peer decision-making support during landmine clearance.  Lastly, we identify several design opportunities for further improving deminers' decision making capabilities.},

pdf = {jayatilaka-chi11.pdf},
publisherversion = {http://dx.doi.org/10.1145/1978942.1979006},
authorizer = {http://dl.acm.org/authorize?406445},
project = {petals},
pubtype = {conference},
}

@inproceedings{gajos10:understanding,
author = {Krzysztof Z. Gajos},
title = {Understanding How to Design Complex Brain-Controlled Applications},
booktitle = {Proceedings of the Workshop on Brain, Body and Bytes: Psychophysiological User Interaction at CHI'10},
year = 2010,
abstract = {<p>Most of the effort in brain-computer interface (BCI) research so far has been directed at developing better sensors and better ways of extracting useful information from the brain signal, while little effort has been directed at systematically understanding the unique strengths and limitations of this input modality and their implications for interaction design.  Past proof of concept brain-controlled applications either involved very simple interaction or they augmented existing complex applications with external widgets to enable limited control.  
</p><p>
This relative lack of research directed at developing applications and interaction methods specifically for brain-computer interfaces is a concern for several reasons. First, some BCI technologies are mature enough to be used soon by large numbers of paralyzed users. Lack of compelling brain-controlled applications or the tools and techniques for building such applications will significantly limit the impact of these technologies. Second, recent work on ability-based user interfaces has demonstrated that large gains in efficiency of interaction and user satisfaction can be achieved if user interfaces are designed with a user's specific abilities and devices in mind. The results of our studies showed that adapting user interfaces to the unique abilities of people with a range of motor impairments helped close the performance gap between those users and able-bodied people by over 60%.  For BCI users, who need up to several tens of seconds to perform a single UI operation, efficiency of interaction will have an even larger impact and will likely determine whether an application is usable in practice. Lastly, a lot of the current research effort in BCI is directed at improving various aspects of the sensing and signal extraction technology. Good understanding of the user interaction requirements of brain-controlled applications will help inform and direct those efforts to maximize their impact on the user experience. 
</p><p>
Motivated by these observations, we are starting a project to explore the properties and limitations of one particularly promising BCI paradigm as an input modality and to develop methods and tools for designing user interfaces for complex brain-controlled applications.</p>
},

pubtype = {workshop},
pdf = {gajos-BrainBodyBytes-2010.pdf},
project = {bci,ability},
image = {papers/images/BCI-thumb.jpg},
}

@article{gajos10:automatically,
title = {Automatically generating personalized user interfaces with {Supple}},
author = {Krzysztof Z. Gajos and Daniel S. Weld and Jacob O. Wobbrock},
journal = {Artificial Intelligence},
year = {2010},
volume = {174},
issue = {12--13},
pages = {910--950},
doi = {doi:10.1016/j.artint.2010.05.005},
publisher = {Elsevier},
abstract = {<p>Today's computer-human interfaces are typically designed with the
assumption that they are going to be used by an able-bodied person,
who is using a typical set of input and output devices, who has
typical perceptual and cognitive abilities, and who is sitting in a
stable, warm environment.  Any deviation from these assumptions may
drastically hamper the person's effectiveness---not because of any
<it>inherent</it> barrier to interaction, but because of a mismatch
between the person's effective abilities and the assumptions underlying the
interface design.</p>
<p>We argue that automatic personalized interface generation is a feasible and
scalable solution to this challenge.  We present our Supple system,
which can automatically generate interfaces adapted to a person's
devices, tasks, preferences, and abilities.  In this paper we formally
define interface generation as an optimization problem and
demonstrate that, despite a large solution space (of up to 10<sup>17</sup> possible interfaces), the problem is computationally feasible.  In fact, for a particular class of cost functions, Supple produces exact solutions in under a second for most cases, and in
a little over a minute in the worst case encountered, thus enabling run-time generation of user interfaces.  We further show
how several different design criteria can be expressed in the cost function,
enabling different kinds of personalization.  We also demonstrate how
this approach enables extensive user- and system-initiated run-time
adaptations to the interfaces after they have been generated.</p>
<p>Supple is not intended to replace human user interface designers---instead, it
offers alternative user interfaces for those people whose devices,
tasks, preferences, and abilities are not sufficiently addressed by
the hand-crafted designs.  Indeed, the results of our
study show that, compared to manufacturers' defaults, interfaces automatically generated by Supple significantly improve speed, accuracy and
satisfaction of people with motor impairments.</p>
},

pubtype = {journal},
pdf = {gajos10supple-aij.pdf},
project = {supple,ability},
publisherversion = {http://dx.doi.org/10.1016/j.artint.2010.05.005},
}

@inproceedings{huang10:toward,
 author = {Huang, Eric and Zhang, Haoqi and Parkes, David C. and Gajos, Krzysztof Z. and Chen, Yiling},
 title = {Toward automatic task design: a progress report},
 booktitle = {Proceedings of the ACM SIGKDD Workshop on Human Computation},
 series = {HCOMP '10},
 year = {2010},
 isbn = {978-1-4503-0222-7},
 location = {Washington DC},
 pages = {77--85},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/1837885.1837908},
 doi = {http://doi.acm.org/10.1145/1837885.1837908},
 acmid = {1837908},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Mechanical Turk, human computation, peer production},
abstract={A central challenge in human computation is in understanding how to design task environments that effectively attract participants and coordinate the problem solving process. In this paper, we consider a common problem that requesters face on Amazon Mechanical Turk: how should a task be designed so as to induce good output from workers? In posting a task, a requester decides how to break down the task into unit tasks, how much to pay for each unit task, and how many workers to assign to a unit task. These design decisions affect the rate at which workers complete unit tasks, as well as the quality of the work that results. Using image labeling as an example task, we consider the problem of designing the task to maximize the number of quality tags received within given time and budget constraints. We consider two different measures of work quality, and construct models for predicting the rate and quality of work based on observations of output to various designs. Preliminary results show that simple models can accurately predict the quality of output per unit task, but are less accurate in predicting the rate at which unit tasks complete. At a fixed rate of pay, our models generate different designs depending on the quality metric, and optimized designs obtain significantly more quality tags than baseline comparisons.},

pubtype = {workshop},
pdf = {huang10hcomp.pdf},
authorizer = {http://dl.acm.org/authorize?372082},
publisherversion = {http://dx.doi.org/10.1145/1837885.1837908},
}


@inproceedings{jayatilaka10:petals,
 author = {Jayatilaka, Lahiru G. and Bertuccelli, Luca F. and Staszewski, James and Gajos, Krzysztof Z.},
 title = {PETALS: a visual interface for landmine detection},
 booktitle = {Adjunct proceedings of the 23nd annual ACM symposium on User interface software and technology},
 series = {UIST '10},
 year = {2010},
 isbn = {978-1-4503-0462-7},
 location = {New York, New York, USA},
 pages = {427--428},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/1866218.1866254},
 doi = {http://doi.acm.org/10.1145/1866218.1866254},
 acmid = {1866254},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {assistive visual interface, humanitarian demining, landmine detection, petals, spatial patterns representation},
abstract = {Post-conflict landmines have serious humanitarian repercussions:
landmines cost lives, limbs and land. The primary
method used to locate these buried devices relies on the inherently
dangerous and difficult task of a human listening to
audio feedback from a metal detector. Researchers have previously
hypothesized that expert operators respond to these
challenges by building mental patterns with metal detectors
through the identification of object-dependent spatially distributed
metallic fields. This paper presents the preliminary
stages of a novel interface---Pattern Enhancement Tool for
Assisting Landmine Sensing (PETALS)---that aims to assist
with building and visualizing these patterns, rather than relying
on memory alone. Simulated demining experiments
show that the experimental interface decreases classification
error from 23% to 5% and reduces localization error by 54%,
demonstrating the potential for PETALS to improve novice
deminer safety and efficiency.},

pdf = {jayatilaka10petals.pdf},
authorizer = {http://dl.acm.org/authorize?393684},
publisherversion = {http://dx.doi.org/10.1145/1866218.1866254},
project = {petals},
pubtype = {poster},
image={http://iis.seas.harvard.edu/projects/images/mines.jpg},
}



@inproceedings{spaulding09:usable,
 author = {Spaulding, Aaron and Gajos, Krzysztof Z. and Jameson, Anthony and Kristensson, Per Ola and Bunt, Andrea and Haines, Will},
 title = {Usable intelligent interactive systems: CHI 2009 special interest group meeting},
 booktitle = {CHI EA '09: Proceedings of the 27th international conference extended abstracts on Human factors in computing systems},
 year = {2009},
 isbn = {978-1-60558-247-4},
 pages = {2743--2746},
 location = {Boston, MA, USA},
 doi = {http://doi.acm.org/10.1145/1520340.1520396},
 publisher = {ACM},
 address = {New York, NY, USA},

abstract = {``The AI and HCI communities have often been characterized as having opposing views of how humans and computers should interact'' observes Winograd in Shifting Viewpoints. It is time to narrow this gap. What was once considered the forefront of artificial intelligence (AI) research can now be found in commercial products. While some have failed, others, such as face detection in digital cameras or product recommendation systems, have become so mainstream they are no longer thought of as artificial intelligence. This special interest group provides a forum to examine the apparent gap between HCI and AI communities, to explore how intelligent technologies can enable novel interaction with computation, and to investigate the challenges associated with understanding human abilities, limitations, and preferences in order to drive the design of intelligent interactive systems.},
pdf = {chi09-SIG-usableiis.pdf},
publisherversion = {http://doi.acm.org/10.1145/1520340.1520396},
pubtype = {other},
 }


@inproceedings{gajos09:beyond,
author = {Krzysztof Z. Gajos},
title = {Beyond Feature Relevance: Incorporating Rich User Feedback Into Interactive Machine Learning Applications},
booktitle = {Proceedings of ADA-IML'09 Workshop at NIPS'09},
year = {2009},

pdf = "adaiml09.pdf",
pubtype = {workshop},
project = {iml},
}

@article{findlater09:design,
author = {Leah Findlater and Krzysztof Z. Gajos},
title = {Design Space and Evaluation Challenges of Adaptive Graphical User Interfaces},
journal = {AI Magazine},
year = {2009},
volume = {30},
number = {4},
pages = {68--73},
 abstract = {Adaptive graphical user interfaces (GUIs) have the potential to improve performance and user satisfaction by automatically tailoring the presentation of functionality to each individual user. In practice, however, many challenges exist, and evaluation results of adaptive GUIs have been mixed. To guide researchers and designers in developing effective adaptive GUIs, we outline a design space and discuss three important aspects to consider when conducting user evaluations of these types of interfaces: the control and reporting of adaptive algorithm characteristics, the impact of task choice and user characteristics on the overall effectiveness of a design, and evaluation measures that are appropriate for adaptive interaction.},

pdf = {AIMag09-AUIs.pdf},
publisherversion = {https://www.aaai.org/ojs/index.php/aimagazine/article/view/2268},
project = {aui},
pubtype = {journal},
}

