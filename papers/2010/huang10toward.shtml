<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<!--#include virtual="../../common-head.html" --> 
<!--#include virtual="../../common-js.html" --> 
<style type="text/css">
a#n-pubs { 
<!--#include virtual="../../common-active-style.html" --> 
}
</style>

<title>Toward automatic task design: a progress report</title>
<meta name="twitter:card" content="summary" />

<meta property="og:title" content="Toward automatic task design: a progress report">
<meta property="og:description" content="A central challenge in human computation is in understanding how to design task environments that effectively attract participants and coordinate the problem solving process. In this paper, we consider a common problem that requesters face on Amazon Mechanical Turk: how should a task be designed so as to induce good output from workers? In posting a task, a requester decides how to break down the task into unit tasks, how much to pay for each unit task, and how many workers to assign to a unit task. These design decisions affect the rate at which workers complete unit tasks, as well as the quality of the work that results. Using image labeling as an example task, we consider the problem of designing the task to maximize the number of quality tags received within given time and budget constraints. We consider two different measures of work quality, and construct models for predicting the rate and quality of work based on observations of output to various designs. Preliminary results show that simple models can accurately predict the quality of output per unit task, but are less accurate in predicting the rate at which unit tasks complete. At a fixed rate of pay, our models generate different designs depending on the quality metric, and optimized designs obtain significantly more quality tags than baseline comparisons.">

 	<script src="media/share.js"></script>
    <script>
        $(function() {
            share.makeButtons("#share");
        });
    </script>
</head>


<body>

<!--#include virtual="../../common-top.html" --> 

<h1 class="head">Toward automatic task design: a progress report</h1>
<h2 class="head">Eric Huang, Haoqi Zhang, David&nbsp;C. Parkes, Krzysztof&nbsp;Z. Gajos, and Yiling Chen</h2>

<!--#include virtual="../../common-nav.html" --> 



<br clear="all"/>

<div style="text-align: right" id="share"></div>


<h3>Abstract</h3>
<div class="content">

A central challenge in human computation is in understanding how to design task environments that effectively attract participants and coordinate the problem solving process. In this paper, we consider a common problem that requesters face on Amazon Mechanical Turk: how should a task be designed so as to induce good output from workers? In posting a task, a requester decides how to break down the task into unit tasks, how much to pay for each unit task, and how many workers to assign to a unit task. These design decisions affect the rate at which workers complete unit tasks, as well as the quality of the work that results. Using image labeling as an example task, we consider the problem of designing the task to maximize the number of quality tags received within given time and budget constraints. We consider two different measures of work quality, and construct models for predicting the rate and quality of work based on observations of output to various designs. Preliminary results show that simple models can accurately predict the quality of output per unit task, but are less accurate in predicting the rate at which unit tasks complete. At a fixed rate of pay, our models generate different designs depending on the quality metric, and optimized designs obtain significantly more quality tags than baseline comparisons.
<br clear="right"/>
</div>




<h3>Available Versions</h3>
<div class="content">
<ul>
<li><a href="papers/2010/huang10hcomp.pdf">Authors' version (pdf)</a></li>
<li><a class="external" href="http://www.eecs.harvard.edu/~kgajos/papers/authorizer.html?url=http://dl.acm.org/authorize?372082">Free access via ACM Authorizer</a></li>
<li><a class="external" href="http://dx.doi.org/10.1145/1837885.1837908">Publisher's version
 (ACM)
</a></li>


<!--??url??<li><a href="##url##">Other</a></li>??/url??-->
</ul>
</div>







<h3>Citation Information</h3>
<div class="content">
<p>Eric Huang, Haoqi Zhang, David&nbsp;C. Parkes, Krzysztof&nbsp;Z. Gajos, and Yiling Chen. Toward automatic task design: a progress report. In <EM>Proceedings of the ACM SIGKDD Workshop on Human Computation</EM>, HCOMP '10, pages 77&ndash;85, New York, NY, USA, 2010. ACM.</p>

<A href='#' class='actionbutton' onclick="var w=window.open('','BibTeX: huang10:toward','scrollbars=yes,menubar=no,height=200,width=600,resizable=yes,toolbar=no,status=no');w.document.writeln('<HTML><HEAD><TITLE>BibTeX: huang10:toward</TITLE></HEAD><BODY><PRE>@inproceedings{huang10:toward,\n  author = {Huang, Eric and Zhang, Haoqi and Parkes, David C. and Gajos, Krzysztof Z. and Chen, Yiling},\n  title = {Toward automatic task design: a progress report},\n  booktitle = {Proceedings of the ACM SIGKDD Workshop on Human Computation},\n  series = {HCOMP \'10},\n  year = {2010},\n  isbn = {978-1-4503-0222-7},\n  location = {Washington DC},\n  pages = {77--85},\n  numpages = {9},\n    doi = {http://doi.acm.org/10.1145/1837885.1837908},\n  acmid = {1837908},\n  publisher = {ACM},\n  address = {New York, NY, USA},\n  keywords = {Mechanical Turk, human computation, peer production},\n  abstract = {A central challenge in human computation is in understanding how to design task environments that effectively attract participants and coordinate the problem solving process. In this paper, we consider a common problem that requesters face on Amazon Mechanical Turk: how should a task be designed so as to induce good output from workers? In posting a task, a requester decides how to break down the task into unit tasks, how much to pay for each unit task, and how many workers to assign to a unit task. These design decisions affect the rate at which workers complete unit tasks, as well as the quality of the work that results. Using image labeling as an example task, we consider the problem of designing the task to maximize the number of quality tags received within given time and budget constraints. We consider two different measures of work quality, and construct models for predicting the rate and quality of work based on observations of output to various designs. Preliminary results show that simple models can accurately predict the quality of output per unit task, but are less accurate in predicting the rate at which unit tasks complete. At a fixed rate of pay, our models generate different designs depending on the quality metric, and optimized designs obtain significantly more quality tags than baseline comparisons.},\n        }\n\n</PRE></BODY></HTML>');w.document.close();return false">BibTeX</A>
</div>

<br clear="all"/>
<hr/>
<div id="share"></div>
</div> <!-- main -->


<!--#include virtual="../../common-footer.html" --> 

</body>
</html>
